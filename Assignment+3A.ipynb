{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Module 3A: Assignment\n",
    "\n",
    "### Weightage: 30 Marks\n",
    "\n",
    "### Assessment task: \n",
    "\n",
    "You work for an AI image company and one of the departments focuses on research into the accurate and timely diagnosis of heart disease, fertility and breast cancer among residents living in Compassvale City. Their research also looks into the risk factors prevalent in this community as whole. Through a state-funded programme, they collect a huge among of anonymous and de-identified data on its residents. However, they face the challenge of making sense of this data. As an upcoming expert in Machine Learning, your assignment is to help the department to make sense of the data and deliver the following solutions.\n",
    "\n",
    "#### Parts\n",
    "\n",
    "1. Programming Part 1: Read the file containing the big heart dataset and display the output of these files\n",
    "\n",
    "2. Programming Part 2: Write a programme that specifies the line of best fit for the fertility rate for workers.\n",
    "\n",
    "3. Programming Part 3: Write a programme that can classify based on radius SE and texture SE of a breast mass and determine whether the diagnosis is mailgnant or benign.\n",
    "\n",
    "4. Programming Part 4: Write a programme that potentially improves the linear regression using regularisation.\n",
    "\n",
    "5. Programming Part 5: Write a programme that can classify two different types of data points with very high accuracy.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Complete all three parts of the assignments by write the Python codes.\n",
    "2. Run your codes to ensure that the required outputs are delivered.\n",
    "3. Submit the assignment for grading and to get feedback.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Programming Part 1: Read the file containing the big heart dataset and display the output of these files\n",
    "\n",
    "\n",
    "\n",
    "### Assessment task:\n",
    "\n",
    "Write a programme that reads the file containing the big heart dataset and display the output of these files. There are 6 steps involved, you will complete the code for step 2 and 4 only.\n",
    "\n",
    "### Marks:\n",
    "This part is of 6 Marks. \n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Write your Python code in place of \"your code here\" placeholder below.\n",
    "2. Run your code by clicking on 'run' cell in the toolbar before you submit.\n",
    "3. You will get the feedback once you submit the assignment.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Click on the submit button on the top right after you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 1\n",
    "Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Load the big heart CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename, skip = False):\n",
    "    dataset = list()\n",
    "    # Opens the file in read only mode\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        \n",
    "        # Skip the header, if needed\n",
    "        if skip:\n",
    "            next(csv_reader, None)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            dataset.append(row)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Print the file's content\n",
    "\n",
    "_Note: This function can be called for other parts in the assignment_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_the_dataset(dataset, contents = True, length = True):\n",
    "    if(contents):\n",
    "        print(tabulate(dataset))\n",
    "        \n",
    "    if(length):\n",
    "        print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "\n",
    "Split the big heart dataset into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset, split):\n",
    "    # Create an empty list for the training set\n",
    "    training = list()\n",
    "    \n",
    "    # Define the size of the training set\n",
    "    train_size = split * len(dataset)\n",
    "    \n",
    "    # Copy the original dataset to \n",
    "    test = list(dataset)\n",
    "    \n",
    "    #Loops only to the size of the training set\n",
    "    while len(training) < train_size:\n",
    "        # Obtain a random index from the dataset/test set\n",
    "        index = randrange(len(test))\n",
    "        \n",
    "        # Populate the training set, by moving the data points from the\n",
    "        # dataset/test set to the training set\n",
    "        training.append(test.pop(index))\n",
    "        \n",
    "    # Return both the training set and test set    \n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "\n",
    "Seed the random value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "\n",
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--  -  -  ---  ---  -  -  ---  -  ---  -  -  -  -\n",
      "43  1  2  130  315  0  1  162  0  1.9  2  1  2  1\n",
      "53  1  2  130  246  1  0  173  0  0    2  3  2  1\n",
      "42  1  3  148  244  0  0  178  0  0.8  2  2  2  1\n",
      "59  1  3  178  270  0  0  145  0  4.2  0  0  3  1\n",
      "63  0  1  140  195  0  1  179  0  0    2  2  2  1\n",
      "42  1  2  120  240  1  1  194  0  0.8  0  0  3  1\n",
      "50  1  2  129  196  0  1  163  0  0    2  0  2  1\n",
      "68  0  2  120  211  0  0  115  0  1.5  1  0  2  1\n",
      "69  1  3  160  234  1  0  131  0  0.1  1  1  2  1\n",
      "45  0  0  138  236  0  0  152  1  0.2  1  0  2  1\n",
      "50  0  1  120  244  0  1  162  0  1.1  2  0  2  1\n",
      "50  0  0  110  254  0  0  159  0  0    2  0  2  1\n",
      "64  0  0  180  325  0  1  154  1  0    2  0  2  1\n",
      "57  1  2  150  126  1  1  173  0  0.2  2  1  3  1\n",
      "64  0  2  140  313  0  1  133  0  0.2  2  0  3  1\n",
      "43  1  0  110  211  0  1  161  0  0    2  0  3  1\n",
      "55  1  1  130  262  0  1  155  0  0    2  0  2  1\n",
      "37  0  2  120  215  0  1  170  0  0    2  0  2  1\n",
      "41  1  2  130  214  0  0  168  0  2    1  0  2  1\n",
      "56  1  3  120  193  0  0  162  0  1.9  1  0  3  1\n",
      "46  0  1  105  204  0  1  172  0  0    2  0  2  1\n",
      "46  0  0  138  243  0  0  152  1  0    1  0  2  1\n",
      "64  0  0  130  303  0  1  122  0  2    1  2  2  1\n",
      "59  1  0  138  271  0  0  182  0  0    2  0  2  1\n",
      "41  0  2  112  268  0  0  172  1  0    2  0  2  1\n",
      "54  0  2  108  267  0  0  167  0  0    2  0  2  1\n",
      "39  0  2   94  199  0  1  179  0  0    2  0  2  1\n",
      "34  0  1  118  210  0  1  192  0  0.7  2  0  2  1\n",
      "47  1  0  112  204  0  1  143  0  0.1  2  0  2  1\n",
      "67  0  2  152  277  0  1  172  0  0    2  1  2  1\n",
      "52  0  2  136  196  0  0  169  0  0.1  1  0  2  1\n",
      "74  0  1  120  269  0  0  121  1  0.2  2  1  2  1\n",
      "54  0  2  160  201  0  1  163  0  0    2  1  2  1\n",
      "49  0  1  134  271  0  1  162  0  0    1  0  2  1\n",
      "42  1  1  120  295  0  1  162  0  0    2  0  2  1\n",
      "41  1  1  110  235  0  1  153  0  0    2  0  2  1\n",
      "41  0  1  126  306  0  1  163  0  0    2  0  2  1\n",
      "49  0  0  130  269  0  1  163  0  0    2  0  2  1\n",
      "60  0  2  120  178  1  1   96  0  0    2  0  2  1\n",
      "62  1  1  128  208  1  0  140  0  0    2  0  2  1\n",
      "57  1  0  110  201  0  1  126  1  1.5  1  0  1  1\n",
      "64  1  0  128  263  0  1  105  1  0.2  1  1  3  1\n",
      "51  0  2  120  295  0  0  157  0  0.6  2  0  2  1\n",
      "43  1  0  115  303  0  1  181  0  1.2  1  0  2  1\n",
      "42  0  2  120  209  0  1  173  0  0    1  0  2  1\n",
      "67  0  0  106  223  0  1  142  0  0.3  2  2  2  1\n",
      "76  0  2  140  197  0  2  116  0  1.1  1  0  2  1\n",
      "70  1  1  156  245  0  0  143  0  0    2  0  2  1\n",
      "44  0  2  118  242  0  1  149  0  0.3  1  1  2  1\n",
      "60  0  3  150  240  0  1  171  0  0.9  2  0  2  1\n",
      "44  1  2  120  226  0  1  169  0  0    2  0  2  1\n",
      "42  1  2  130  180  0  1  150  0  0    2  0  2  1\n",
      "66  1  0  160  228  0  0  138  0  2.3  2  0  1  1\n",
      "71  0  0  112  149  0  1  125  0  1.6  1  0  2  1\n",
      "64  1  3  170  227  0  0  155  0  0.6  1  0  3  1\n",
      "66  0  2  146  278  0  0  152  0  0    1  1  2  1\n",
      "39  0  2  138  220  0  1  152  0  0    1  0  2  1\n",
      "58  0  0  130  197  0  1  131  0  0.6  1  0  2  1\n",
      "47  1  2  130  253  0  1  179  0  0    2  0  2  1\n",
      "35  1  1  122  192  0  1  174  0  0    2  0  2  1\n",
      "58  1  1  125  220  0  1  144  0  0.4  1  4  3  1\n",
      "56  1  1  130  221  0  0  163  0  0    2  0  3  1\n",
      "56  1  1  120  240  0  1  169  0  0    0  0  2  1\n",
      "55  0  1  132  342  0  1  166  0  1.2  2  0  2  1\n",
      "41  1  1  120  157  0  1  182  0  0    2  0  2  1\n",
      "38  1  2  138  175  0  1  173  0  0    2  4  2  1\n",
      "38  1  2  138  175  0  1  173  0  0    2  4  2  1\n",
      "67  1  0  160  286  0  0  108  1  1.5  1  3  2  0\n",
      "67  1  0  120  229  0  0  129  1  2.6  1  2  3  0\n",
      "62  0  0  140  268  0  0  160  0  3.6  0  2  2  0\n",
      "63  1  0  130  254  0  0  147  0  1.4  1  1  3  0\n",
      "53  1  0  140  203  1  0  155  1  3.1  0  0  3  0\n",
      "56  1  2  130  256  1  0  142  1  0.6  1  1  1  0\n",
      "48  1  1  110  229  0  1  168  0  1    0  0  3  0\n",
      "58  1  1  120  284  0  0  160  0  1.8  1  0  2  0\n",
      "58  1  2  132  224  0  0  173  0  3.2  2  2  3  0\n",
      "60  1  0  130  206  0  0  132  1  2.4  1  2  3  0\n",
      "40  1  0  110  167  0  0  114  1  2    1  0  3  0\n",
      "60  1  0  117  230  1  1  160  1  1.4  2  2  3  0\n",
      "64  1  2  140  335  0  1  158  0  0    2  0  2  0\n",
      "43  1  0  120  177  0  0  120  1  2.5  1  0  3  0\n",
      "57  1  0  150  276  0  0  112  1  0.6  1  1  1  0\n",
      "55  1  0  132  353  0  1  132  1  1.2  1  1  3  0\n",
      "65  0  0  150  225  0  0  114  0  1    1  3  3  0\n",
      "61  0  0  130  330  0  0  169  0  0    2  0  2  0\n",
      "58  1  2  112  230  0  0  165  0  2.5  1  1  3  0\n",
      "50  1  0  150  243  0  0  128  0  2.6  1  0  3  0\n",
      "44  1  0  112  290  0  0  153  0  0    2  1  2  0\n",
      "60  1  0  130  253  0  1  144  1  1.4  2  1  3  0\n",
      "54  1  0  124  266  0  0  109  1  2.2  1  1  3  0\n",
      "50  1  2  140  233  0  1  163  0  0.6  1  1  3  0\n",
      "41  1  0  110  172  0  0  158  0  0    2  0  3  0\n",
      "51  0  0  130  305  0  1  142  1  1.2  1  0  3  0\n",
      "58  1  0  128  216  0  0  131  1  2.2  1  3  3  0\n",
      "54  1  0  120  188  0  1  113  0  1.4  1  1  3  0\n",
      "60  1  0  145  282  0  0  142  1  2.8  1  2  3  0\n",
      "60  1  2  140  185  0  0  155  0  3    1  0  2  0\n",
      "59  1  0  170  326  0  0  140  1  3.4  0  0  3  0\n",
      "46  1  2  150  231  0  1  147  0  3.6  1  0  2  0\n",
      "67  1  0  125  254  1  1  163  0  0.2  1  2  3  0\n",
      "62  1  0  120  267  0  1   99  1  1.8  1  2  3  0\n",
      "65  1  0  110  248  0  0  158  0  0.6  2  2  1  0\n",
      "44  1  0  110  197  0  0  177  0  0    2  1  2  0\n",
      "60  1  0  125  258  0  0  141  1  2.8  1  1  3  0\n",
      "58  1  0  150  270  0  0  111  1  0.8  2  0  3  0\n",
      "68  1  2  180  274  1  0  150  1  1.6  1  0  3  0\n",
      "62  0  0  160  164  0  0  145  0  6.2  0  3  3  0\n",
      "52  1  0  128  255  0  1  161  1  0    2  1  3  0\n",
      "59  1  0  110  239  0  0  142  1  1.2  1  1  3  0\n",
      "60  0  0  150  258  0  0  157  0  2.6  1  2  3  0\n",
      "49  1  2  120  188  0  1  139  0  2    1  3  3  0\n",
      "59  1  0  140  177  0  1  162  1  0    2  1  3  0\n",
      "57  1  2  128  229  0  0  150  0  0.4  1  1  3  0\n",
      "61  1  0  120  260  0  1  140  1  3.6  1  1  3  0\n",
      "39  1  0  118  219  0  1  140  0  1.2  1  0  3  0\n",
      "61  0  0  145  307  0  0  146  1  1    1  0  3  0\n",
      "56  1  0  125  249  1  0  144  1  1.2  1  1  2  0\n",
      "43  0  0  132  341  1  0  136  1  3    1  0  3  0\n",
      "62  0  2  130  263  0  1   97  0  1.2  1  1  3  0\n",
      "63  1  0  130  330  1  0  132  1  1.8  2  3  3  0\n",
      "65  1  0  135  254  0  0  127  0  2.8  1  1  3  0\n",
      "48  1  0  130  256  1  0  150  1  0    2  2  3  0\n",
      "63  0  0  150  407  0  0  154  0  4    1  3  3  0\n",
      "55  1  0  140  217  0  1  111  1  5.6  0  0  3  0\n",
      "65  1  3  138  282  1  0  174  0  1.4  1  1  2  0\n",
      "56  0  0  200  288  1  0  133  1  4    0  2  3  0\n",
      "54  1  0  110  239  0  1  126  1  2.8  1  1  3  0\n",
      "70  1  0  145  174  0  1  125  1  2.6  0  0  3  0\n",
      "62  1  1  120  281  0  0  103  0  1.4  1  1  3  0\n",
      "35  1  0  120  198  0  1  130  1  1.6  1  0  3  0\n",
      "59  1  3  170  288  0  0  159  0  0.2  1  0  3  0\n",
      "64  1  2  125  309  0  1  131  1  1.8  1  0  3  0\n",
      "47  1  2  108  243  0  1  152  0  0    2  0  2  0\n",
      "57  1  0  165  289  1  0  124  0  1    1  3  3  0\n",
      "55  1  0  160  289  0  0  145  1  0.8  1  1  3  0\n",
      "64  1  0  120  246  0  0   96  1  2.2  0  1  2  0\n",
      "70  1  0  130  322  0  0  109  0  2.4  1  3  2  0\n",
      "51  1  0  140  299  0  1  173  1  1.6  2  0  3  0\n",
      "58  1  0  125  300  0  0  171  0  0    2  2  3  0\n",
      "60  1  0  140  293  0  0  170  0  1.2  1  2  3  0\n",
      "77  1  0  125  304  0  0  162  1  0    2  3  2  0\n",
      "35  1  0  126  282  0  0  156  1  0    2  0  3  0\n",
      "70  1  2  160  269  0  1  112  1  2.9  1  1  3  0\n",
      "59  0  0  174  249  0  1  143  1  0    1  0  2  0\n",
      "64  1  0  145  212  0  0  132  0  2    1  2  1  0\n",
      "57  1  0  152  274  0  1   88  1  1.2  1  1  3  0\n",
      "56  1  0  132  184  0  0  105  1  2.1  1  1  1  0\n",
      "48  1  0  124  274  0  0  166  0  0.5  1  0  3  0\n",
      "56  0  0  134  409  0  0  150  1  1.9  1  2  3  0\n",
      "66  1  1  160  246  0  1  120  1  0    1  3  1  0\n",
      "54  1  1  192  283  0  0  195  0  0    2  1  3  0\n",
      "69  1  2  140  254  0  0  146  0  2    1  3  3  0\n",
      "51  1  0  140  298  0  1  122  1  4.2  1  3  3  0\n",
      "43  1  0  132  247  1  0  143  1  0.1  1  4  3  0\n",
      "62  0  0  138  294  1  1  106  0  1.9  1  3  2  0\n",
      "67  1  0  100  299  0  0  125  1  0.9  1  2  2  0\n",
      "59  1  3  160  273  0  0  125  0  0    2  0  2  0\n",
      "45  1  0  142  309  0  0  147  1  0    1  3  3  0\n",
      "58  1  0  128  259  0  0  130  1  3    1  2  3  0\n",
      "50  1  0  144  200  0  0  126  1  0.9  1  0  3  0\n",
      "62  0  0  150  244  0  1  154  1  1.4  1  0  2  0\n",
      "38  1  3  120  231  0  1  182  1  3.8  1  0  3  0\n",
      "66  0  0  178  228  1  1  165  1  1    1  2  3  0\n",
      "52  1  0  112  230  0  1  160  0  0    2  1  2  0\n",
      "53  1  0  123  282  0  1   95  1  2    1  2  3  0\n",
      "63  0  0  108  269  0  1  169  1  1.8  1  2  2  0\n",
      "54  1  0  110  206  0  0  108  1  0    1  1  2  0\n",
      "66  1  0  112  212  0  0  132  1  0.1  2  1  2  0\n",
      "55  0  0  180  327  0  2  117  1  3.4  1  0  2  0\n",
      "49  1  2  118  149  0  0  126  0  0.8  2  3  2  0\n",
      "54  1  0  122  286  0  0  116  1  3.2  1  2  2  0\n",
      "56  1  0  130  283  1  0  103  1  1.6  0  0  3  0\n",
      "46  1  0  120  249  0  0  144  0  0.8  2  0  3  0\n",
      "61  1  3  134  234  0  1  145  0  2.6  1  2  2  0\n",
      "67  1  0  120  237  0  1   71  0  1    1  0  2  0\n",
      "58  1  0  100  234  0  1  156  0  0.1  2  1  3  0\n",
      "47  1  0  110  275  0  0  118  1  1    1  1  2  0\n",
      "52  1  0  125  212  0  1  168  0  1    2  2  3  0\n",
      "58  1  0  146  218  0  1  105  0  2    1  1  3  0\n",
      "57  1  1  124  261  0  1  141  0  0.3  2  0  3  0\n",
      "58  0  1  136  319  1  0  152  0  0    2  2  2  0\n",
      "61  1  0  138  166  0  0  125  1  3.6  1  1  2  0\n",
      "42  1  0  136  315  0  1  125  1  1.8  1  0  1  0\n",
      "52  1  0  128  204  1  1  156  1  1    1  0  0  0\n",
      "59  1  2  126  218  1  1  134  0  2.2  1  1  1  0\n",
      "40  1  0  152  223  0  1  181  0  0    2  0  3  0\n",
      "61  1  0  140  207  0  0  138  1  1.9  2  1  3  0\n",
      "46  1  0  140  311  0  1  120  1  1.8  1  2  3  0\n",
      "59  1  3  134  204  0  1  162  0  0.8  2  2  2  0\n",
      "57  1  1  154  232  0  0  164  0  0    2  1  2  0\n",
      "57  1  0  110  335  0  1  143  1  3    1  1  3  0\n",
      "55  0  0  128  205  0  2  130  1  2    1  1  3  0\n",
      "61  1  0  148  203  0  1  161  0  0    2  1  3  0\n",
      "58  1  0  114  318  0  2  140  0  4.4  0  3  1  0\n",
      "58  0  0  170  225  1  0  146  1  2.8  1  2  1  0\n",
      "67  1  2  152  212  0  0  150  0  0.8  1  0  3  0\n",
      "44  1  0  120  169  0  1  144  1  2.8  0  0  1  0\n",
      "63  1  0  140  187  0  0  144  1  4    2  2  3  0\n",
      "63  0  0  124  197  0  1  136  1  0    1  0  2  0\n",
      "59  1  0  164  176  1  0   90  0  1    1  2  1  0\n",
      "57  0  0  140  241  0  1  123  1  0.2  1  0  3  0\n",
      "45  1  3  110  264  0  1  132  0  1.2  1  0  3  0\n",
      "68  1  0  144  193  1  1  141  0  3.4  1  2  3  0\n",
      "57  1  0  130  131  0  1  115  1  1.2  1  1  3  0\n",
      "57  0  1  130  236  0  0  174  0  0    1  1  2  0\n",
      "--  -  -  ---  ---  -  -  ---  -  ---  -  -  -  -\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "filename = 'big_heart.csv'\n",
    "\n",
    "dataset = load_csv(filename, skip = True)\n",
    "print_the_dataset(dataset)\n",
    "training, test = train_test_split(dataset, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "print(len(training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 1.1",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 1.2",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Programming Part 2: Linear Regression\n",
    "\n",
    "Write a programme that specifies the line of best fit for the fertility rate for workers.\n",
    "\n",
    "\n",
    "### Assessment task:\n",
    "\n",
    "Write code to analyse the relationships between the variables in a dataset between the percentage of female workers and the fertility rate of women. There are 13 steps involved, you will complete the code for steps 2, 3, 4, 5, 6, 7 and 9 only.\n",
    "\n",
    "### Marks:\n",
    "\n",
    "This part is of 6 Marks. \n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Write your Python code in place of \"your code here\" placeholder below.\n",
    "2. Run your code by clicking on 'run' cell in the toolbar before you submit.\n",
    "3. You will get the feedback once you submit the assignment.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Click on the submit button on the top right after you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 1\n",
    "\n",
    "Import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from matplotlib import pyplot as plot\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 2\n",
    "\n",
    "Load a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename, skip = False):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        \n",
    "        # Skip the header, if needed\n",
    "        if skip:\n",
    "            next(csv_reader, None)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 3\n",
    "\n",
    "Convert string column to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_column_to_float(dataset, column):\n",
    " \n",
    "    for row in dataset:\n",
    "                row[column] = float(row[column].strip())\n",
    "\n",
    "        # The strip() function remove white space\n",
    "        # then convert the data into a decimal number (float)\n",
    "        # and overwrite the original data\n",
    "        \n",
    "        ###\n",
    "        ### YOUR CODE HERE\n",
    "        ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 4\n",
    "\n",
    "Calculate the mean value of a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(values):\n",
    "    mean_results = sum(values) / float(len(values))\n",
    "    return mean_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "\n",
    "Calculate least squares between x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leastSquares(dataset):\n",
    "    x = list()\n",
    "    y = list()\n",
    "\n",
    "    for row in dataset:\n",
    "        x.append(row[0])\n",
    "        y.append(row[1])\n",
    "\n",
    "    # Calculate the means of x and y\n",
    "    mean_x = sum(x) / len(x)\n",
    "    mean_y = sum(y) / len(y)\n",
    "\n",
    "    # Calculate the coefficients b0 and b1 for the line of best fit\n",
    "    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(len(x)))\n",
    "    denominator = sum((x[i] - mean_x) ** 2 for i in range(len(x)))\n",
    "\n",
    "    b1 = numerator / denominator\n",
    "    b0 = mean_y - b1 * mean_x\n",
    "\n",
    "    return [b0, b1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "\n",
    "Calculate root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_mean_square_error(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    \n",
    "    # Loops through the difference between the prediction\n",
    "    # and the actual output\n",
    "    # Then update the sum error\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error = sum_error + (prediction_error ** 2)\n",
    "    \n",
    "    # Take the average\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    \n",
    "    return sqrt(mean_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "\n",
    "Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression(train, test):\n",
    "\n",
    "    predictions = list()\n",
    "    b0, b1 = leastSquares(train)\n",
    "    \n",
    "    # Calculate the prediction (yhat)\n",
    "    for row in test:\n",
    "        x = row[0]  # Extract the x value from the test data\n",
    "        yhat = b0 + b1 * x  # Calculate the predicted y value (yhat)\n",
    "        predictions.append(yhat)  # Append the prediction to the list\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "\n",
    "Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset, split):\n",
    "    train = list()\n",
    "    train_size = split * len(dataset)\n",
    "    test = list(dataset)\n",
    "\n",
    "    while len(train) < train_size:\n",
    "        index = randrange(len(test))\n",
    "        train.append(test.pop(index))\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "\n",
    "Evaluate regression algorithm on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_simple_linear_regression(dataset, split=0):\n",
    "    test_set = list()\n",
    "    train, test = train_test_split(dataset, split)\n",
    "    \n",
    "    for row in dataset:\n",
    "        row_copy = list(row)\n",
    "        row_copy[-1] = None\n",
    "        test_set.append(row_copy)\n",
    "        \n",
    "    if(split == 0):\n",
    "        predicted = simple_linear_regression(dataset, test_set)\n",
    "    else:\n",
    "        predicted = simple_linear_regression(train, test_set)\n",
    "        \n",
    "    if(split == 0):\n",
    "        actual = [row[-1] for row in dataset]\n",
    "    else:\n",
    "        actual = [row[-1] for row in test]\n",
    "    \n",
    "    rmse = root_mean_square_error(actual, predicted)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10\n",
    "\n",
    "Visualise the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualise_dataset(dataset):\n",
    "    test_set = list()\n",
    "    \n",
    "    for row in dataset:\n",
    "        row_copy = list(row)\n",
    "        row_copy[-1] = None\n",
    "        test_set.append(row_copy)\n",
    "    \n",
    "    sizes, prices = [], []\n",
    "    for i in range(len(dataset)):\n",
    "        sizes.append(dataset[i][0])\n",
    "        prices.append(dataset[i][1])\n",
    "        \n",
    "    plot.figure()\n",
    "    plot.plot(sizes, prices, 'x')\n",
    "    plot.plot(test_set, simple_linear_regression(dataset, test_set))\n",
    "    plot.xlabel('Size')\n",
    "    plot.ylabel('Price')\n",
    "    plot.grid()\n",
    "    plot.tight_layout()\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "Seed the random value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "\n",
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'fertility_rate-worker_percent.csv'\n",
    "dataset = load_csv(filename, skip=True)\n",
    "\n",
    "for i in range(len(dataset[0])):\n",
    "    string_column_to_float(dataset, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13\n",
    "\n",
    "Evaluate algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error: 3.232\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = 0.6\n",
    "rmse = evaluate_simple_linear_regression(dataset, split)\n",
    "\n",
    "print('Root Mean Square Error: %.3f' % rmse)\n",
    "visualise_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 2.1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 2.2",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 2.3",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Part 3: Logistic Regression\n",
    "\n",
    "Write a programme that can classify a digitized image of a fine needle aspirate (FNA) of a breast mass and determine whether the diagnosis is mailgnant or benign.\n",
    "\n",
    "\n",
    "### Assessment task:\n",
    "\n",
    "Write code to produce classification graphs and determine the accurary. There are 14 steps involved, you will complete the code for steps 3, 4, 5, 6, 7, 8, 10, 11 and 12 only.\n",
    "\n",
    "### Marks:\n",
    "\n",
    "This part is of 6 Marks. \n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Write your Python code in place of \"your code here\" placeholder below.\n",
    "2. Run your code by clicking on 'run' cell in the toolbar before you submit.\n",
    "3. You will get the feedback once you submit the assignment.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Click on the submit button on the top right after you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import exp\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "Import extra libraries, only needed for displaying the classification graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.arraysetops import unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "Load a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename, skip=False):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        if skip:\n",
    "            next(csv_reader, None)\n",
    "        for row in csv_reader:\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "Convert string diagnosis to number\n",
    "\n",
    "Assign the diagnosis of mailgnant (M) to 0 and assign the diagnosis of benign (B) to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diagnosis_column_to_number(dataset, column):\n",
    "    for row in dataset:\n",
    "        if row[column] == 'M':\n",
    "            row[column] = 0\n",
    "        elif row[column] == 'B':\n",
    "            row[column] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "Extract only the x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_only_x_data(dataset):\n",
    "    data = list()\n",
    "    for row in dataset:\n",
    "        x_data = row[1:-1]  \n",
    "        data.append(x_data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "Extract only the y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_only_y_data(dataset):\n",
    "    data = list()\n",
    "    for row in dataset:\n",
    "        y_data = row[-1]  \n",
    "        data.append(y_data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "Define sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sigmoid_result = 1 / (1 + np.exp(-z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    n = len(y)\n",
    "    loss = (-1/n) * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "Define gradients function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "    \n",
    "    # X Input.\n",
    "    # y true/target value.\n",
    "    # y_hat predictions.\n",
    "    # w weights.\n",
    "    # b bias.\n",
    "    \n",
    "    # number of training examples.\n",
    "    numner_of_examples = X.shape[0]\n",
    "    \n",
    "    # Gradient of loss weights.\n",
    "    dw = (1/numner_of_examples)*np.dot(X.T, (y_hat - y))\n",
    "    \n",
    "    # Gradient of loss bias.\n",
    "    db = (1/numner_of_examples)*np.sum((y_hat - y)) \n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10\n",
    "Train the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, y, batch_size, epochs, learning_rate):\n",
    "    \n",
    "    # X Input.\n",
    "    # y true/target value.\n",
    "    # batch_size Batch Size.\n",
    "    # epochs Number of iterations.\n",
    "    # learning_rate Learning rate.\n",
    "        \n",
    "    # number of training examples\n",
    "    # number of features \n",
    "    numner_of_examples, numner_of_features = X.shape\n",
    "    \n",
    "    # Initializing weights and bias to zeros.\n",
    "    weights = np.zeros((numner_of_features,1))\n",
    "    bias = 0\n",
    "    \n",
    "    # Reshaping y.\n",
    "    y = y.reshape(numner_of_examples,1)\n",
    "    \n",
    "    # Empty list to store losses.\n",
    "    losses = []\n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((numner_of_examples-1)//batch_size + 1):\n",
    "            \n",
    "            # Defining batches. SGD.\n",
    "            start_i = i * batch_size\n",
    "            end_i = start_i + batch_size\n",
    "            xb = X[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            \n",
    "            # Calculating hypothesis/prediction.\n",
    "            y_hat = sigmoid(np.dot(xb, weights) + bias)\n",
    "            print(y_hat)\n",
    "            \n",
    "            # Getting the gradients of loss w.r.t parameters.\n",
    "            dw, db = gradients(xb, yb, y_hat)\n",
    "            \n",
    "            # Updating the parameters.\n",
    "            weights -= learning_rate * dw\n",
    "            bias -= learning_rate * db\n",
    "\n",
    "        # Calculating loss and appending it in the list.\n",
    "        l = loss(y, sigmoid(np.dot(X, weights) + bias))\n",
    "        losses.append(l)\n",
    "        \n",
    "    # returning weights, bias and losses(List).\n",
    "    return weights, bias, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    \n",
    "    # X Input.\n",
    "    \n",
    "    # Calculating presictions/y_hat.\n",
    "    preds = sigmoid(np.dot(X, w) + b)\n",
    "    \n",
    "    # Empty List to store predictions.\n",
    "    pred_class = []\n",
    "    \n",
    "    # DELETE the following two lines and replace it with your own code\n",
    "    # Otherwise leaving this code will pollute your predictions \n",
    "    \n",
    "        \n",
    "    # if y_hat >= 0.5 round up to 1\n",
    "    # if y_hat < 0.5 round down to 0\n",
    "    \n",
    "    for i in preds:\n",
    "        if i >= 0.5:\n",
    "            pred_class.append(1)\n",
    "        else:\n",
    "            pred_class.append(0)\n",
    "\n",
    "    \n",
    "    return np.array(pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "Obtain the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    correct = 0\n",
    "    n = len(y)\n",
    "\n",
    "    for i in range(n):\n",
    "        if y[i] == y_hat[i]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / n\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13\n",
    "Output the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, w, b):\n",
    "    \n",
    "    # X Inputs\n",
    "    # w weights\n",
    "    # b bias\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"g^\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([0, 2.2])\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "    plt.title('Decision Boundary')\n",
    "    \n",
    "    # The Line is y=mx+c\n",
    "    # So, Equate mx+c = w.X + b\n",
    "    # Solving we find m and c\n",
    "    x1 = [min(X[:,0]), max(X[:,0])]\n",
    "    \n",
    "    if(w[1] != 0):\n",
    "        m = -w[0]/w[1]\n",
    "        c = -b/w[1]\n",
    "        x2 = m*x1 + c\n",
    "        plt.plot(x1, x2, 'y-')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 14\n",
    "Evaluate algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data type must provide an itemsize",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-db630dc3b1f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# Plotting Decision Boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-8d944f3405d5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, y, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Calculating hypothesis/prediction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: data type must provide an itemsize"
     ]
    }
   ],
   "source": [
    "filename = 'breast_cancer_data.csv'\n",
    "dataset = load_csv(filename, skip=True)\n",
    "\n",
    "diagnosis_column_to_number(dataset, 2)\n",
    "\n",
    "X_train_data = extract_only_x_data(dataset)\n",
    "y_train_data = extract_only_y_data(dataset)\n",
    "\n",
    "X = np.array(X_train_data)\n",
    "y = np.array(y_train_data)\n",
    "\n",
    "\n",
    "\n",
    "# Training \n",
    "w, b, l = train(X, y, batch_size=100, epochs=1000, learning_rate=0.01)\n",
    "# Plotting Decision Boundary\n",
    "plot_decision_boundary(X, w, b)\n",
    "\n",
    "accuracy(y, y_hat=predict(X, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 3.1",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 3.2",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Part 4: Regularisation\n",
    "\n",
    "Write a programme that potentially improves the previous linear regression using regularisation.\n",
    "\n",
    "\n",
    "### Assessment task:\n",
    "\n",
    "Write code to improve the previous linear regression using a elastic net regularisation. There are 12 steps involved, you will complete the code for steps 2, 4, 5, 6 and 7 only.\n",
    "\n",
    "### Marks:\n",
    "\n",
    "This part is of 6 Marks.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Write your Python code in place of \"your code here\" placeholder below.\n",
    "2. Run your code by clicking on 'run' cell in the toolbar before you submit.\n",
    "3. You will get the feedback once you submit the assignment.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Click on the submit button on the top right after you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 1\n",
    "\n",
    "Import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from matplotlib import pyplot as plot\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 2\n",
    "\n",
    "Load a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename, skip = False):\n",
    "    dataset = list()\n",
    "    # Opens the file in read only mode\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        \n",
    "        # Skip the header, if needed\n",
    "        if skip:\n",
    "            next(csv_reader, None)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            dataset.append(row)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'fertility_rate-worker_percent.csv'\n",
    "dataset = load_csv(filename, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3.71', '28.33'], ['3.59', '28.72'], ['3.48', '29.18'], ['3.37', '29.67'], ['3.27', '30.17'], ['3.17', '30.66'], ['3.07', '31.02'], ['2.97', '31.40'], ['2.88', '31.77'], ['2.78', '32.13'], ['2.69', '32.50'], ['2.60', '32.74'], ['2.52', '33.50'], ['2.45', '34.29'], ['2.38', '35.10'], ['2.32', '35.94'], ['2.27', '36.77'], ['2.23', '37.62'], ['2.19', '38.49'], ['2.15', '39.38'], ['2.12', '40.29'], ['2.09', '41.21'], ['2.06', '44.04']]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 3\n",
    "\n",
    "Convert string column to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        # The strip() function remove white space\n",
    "        # then convert the data into a decimal number (float)\n",
    "        # and overwrite the original data\n",
    "        row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 4\n",
    "\n",
    "Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, b, W) :\n",
    "    y_hat = np.dot(X, W) + b\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Step 5\n",
    "\n",
    "Update the weights with the gradients and L2 penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(X, Y, b, W, no_of_training_examples, learning_rate, l2_penality):\n",
    "    # Calculate the predictions\n",
    "    y_hat = np.dot(X, W) + b\n",
    "    \n",
    "    # Calculate the errors\n",
    "    errors = y_hat - Y\n",
    "    \n",
    "    # Compute the gradients with respect to the weights\n",
    "    gradient_w = (1/no_of_training_examples) * np.dot(X.T, errors)\n",
    "    \n",
    "    # Compute the gradient with respect to the bias\n",
    "    gradient_b = (1/no_of_training_examples) * np.sum(errors)\n",
    "    \n",
    "    # Update the weights with L2 penalty\n",
    "    W = (1 - 2 * learning_rate * l2_penality) * W - learning_rate * gradient_w\n",
    "    \n",
    "    # Update the bias\n",
    "    b = b - learning_rate * gradient_b\n",
    "    \n",
    "    return b, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "\n",
    "Linear Regression with L2 (Ridge) Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(X, Y, iterations = 1000, learning_rate = 0.01, l2_penality = 1):\n",
    "    # Initialize weights and bias\n",
    "    num_examples, num_features = X.shape\n",
    "    W = np.zeros((num_features, 1))\n",
    "    b = 0\n",
    "    \n",
    "    # Gradient Descent\n",
    "    for i in range(iterations):\n",
    "        # Calculate predictions\n",
    "        y_hat = np.dot(X, W) + b\n",
    "        \n",
    "        # Calculate errors\n",
    "        errors = y_hat - Y\n",
    "        \n",
    "        # Compute gradients with respect to weights\n",
    "        gradient_w = (1/num_examples) * np.dot(X.T, errors)\n",
    "        \n",
    "        # Compute gradient with respect to bias\n",
    "        gradient_b = (1/num_examples) * np.sum(errors)\n",
    "        \n",
    "        # Update weights with L2 penalty\n",
    "        W = (1 - 2 * learning_rate * l2_penality) * W - learning_rate * gradient_w\n",
    "        \n",
    "        # Update bias\n",
    "        b = b - learning_rate * gradient_b\n",
    "    \n",
    "    return b, W\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "\n",
    "Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_test_split(dataset, split):\n",
    "    # Convert the dataset to a NumPy array\n",
    "    data = np.array(dataset)\n",
    "    \n",
    "    # Shuffle the data randomly\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    # Determine the split index based on the given split percentage\n",
    "    split_index = int(len(data) * split)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train = data[:split_index, :-1]  # Features for training\n",
    "    Y_train = data[:split_index, -1]   # Labels for training\n",
    "    X_test = data[split_index:, :-1]   # Features for testing\n",
    "    Y_test = data[split_index:, -1]    # Labels for testing\n",
    "        \n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "\n",
    "Perform regression algorithm on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_ridge_regression(dataset, split):\n",
    "    \n",
    "    # Spilt the data in training and test sets\n",
    "    # And split further in X_train, Y_train, X_test, Y_test    \n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = train_test_split(dataset, split)\n",
    "\n",
    "    # Train the model\n",
    "        \n",
    "    b, W = ridge_regression(X_train, Y_train, iterations = 10000, l2_penality = 0.001)\n",
    "    \n",
    "    # Make a prediction with the model\n",
    "           \n",
    "    yhat = predict(X_test, b, W)\n",
    "    \n",
    "    # Round the trained weights\n",
    "    rounded_W = np.round(W, 2)\n",
    "    \n",
    "    print(W)\n",
    "        \n",
    "    print( \"Predicted values \", np.round( yhat[:3], 2 ) )\n",
    "    print( \"Real values      \", Y_test[:3] ) \n",
    "    print( \"Trained W        \", np.round( W[0], 2 ) )    \n",
    "    print( \"Trained b        \", np.round( b, 2 ) )\n",
    "\n",
    "    visualise(X_test, Y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "\n",
    "Visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualise(X_test, Y_test, yhat):\n",
    "    plot.scatter( X_test, Y_test, color = 'blue' )    \n",
    "    plot.plot( X_test, yhat, color = 'orange' )    \n",
    "    plot.title( 'Fertility Rate vs Worker Percentage' )    \n",
    "    plot.xlabel('Fertility Rate')\n",
    "    plot.ylabel('Worker Percentage')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10\n",
    "\n",
    "Seed the random value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'fertility_rate-worker_percent.csv'\n",
    "dataset = load_csv(filename, skip=True)\n",
    "\n",
    "for i in range(len(dataset[0])):\n",
    "    string_column_to_float(dataset, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "\n",
    "Evaluate regression algorithm on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.85198732 -1.18764029  2.15936894 -0.91684666  0.88844419 -1.31762123\n",
      "   1.19534363 -1.05043819 -0.6532742  -0.29221603  2.49154246  1.50946424\n",
      "  -0.78686572  1.83080601 -2.01807408]]\n",
      "Predicted values  [[27.44 29.9  42.32 30.91 37.61 29.42 38.74 30.41 31.89 33.23 43.55 39.91\n",
      "  31.39 41.1  26.82]\n",
      " [30.01 31.55 39.32 32.18 36.37 31.25 37.08 31.87 32.79 33.63 40.09 37.81\n",
      "  32.48 38.56 29.63]\n",
      " [30.49 31.86 38.76 32.42 36.14 31.6  36.77 32.15 32.96 33.71 39.44 37.42\n",
      "  32.69 38.08 30.15]]\n",
      "Real values       [28.33 35.94 44.04]\n",
      "Trained W         [-1.85 -1.19  2.16 -0.92  0.89 -1.32  1.2  -1.05 -0.65 -0.29  2.49  1.51\n",
      " -0.79  1.83 -2.02]\n",
      "Trained b         34.31\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABRaklEQVR4nO2debhdZXX/P+vO83wzzyEMASFACBBEwiSoCGi11aIVh6LWVq21VcqvQlWsWltr64A4oW0UEAQRQQWZw2QCYQokQMgcMid3Hs/6/fHuk7PPuWfY59wz3rs+z7OfPZz97v2efc99v3u9a73rFVXFMAzDMJJRVugKGIZhGMWPiYVhGIaREhMLwzAMIyUmFoZhGEZKTCwMwzCMlJhYGIZhGCkxsTCSIiLXici/eNsrRGSb77MXRGRFoeo2mRCRa0Tk/wpdD2PyYmIxARCRTSLSLyI9vmVGBte5XEQe8R9T1Y+p6pfina+qx6rqA17ZcTVmIvKAiAx4dd8rIr8SkekBy0aJWCEQkStF5O6YYy8nOPae/NYuOSJyg4gMec9+v4jcIyJHF7peYYrh72uYWEwk3q6qDb5lRzqFRaQiVxVLg79V1QbgCKAB+EaB65MODwHLRaQcwBO6SuDEmGNHeOcGJpt/myTX+rr37GcBu4EbsnhtYwJgYjGBEZFmEfmRiOwUke0i8mVfw3W5iKwSkW+KyD7gJuA64HTvDfOgd94NIvLlBNffJCLniciFwD8Df+GVfUZE3i0ia2LO/4yI/DpVvVX1IHA7sMRX9oMi8qKIdIvIRhH5qHe8HrgbmOG3qkSkTEQ+LyKvisg+EblZRNoSfI8XReQi336FiOwRkZNEpEZE/s+7xkER+ZOITI1zmT/hxCFc5zOB+4H1McdeVdUdXh3v8N7kXxGRv/bd/xoRucW7bxdweUx9K0XkFyJyq4hUede61avzayLyyaDXivPs+4CfA8d55dO6toi0ichPRGSHiBwQkdt9518kImu95/ioiBzv+2yTiHxWRJ4VkUMicpP37BP9fZeJyGPetXaKyLdFpMp3vTeLyHrvWt8VkQdF5CO+zz/k/d0PiMjvRWRusudimFhMdG4ARnBvsycCbwY+4vv8VGAjMBV4H/Ax4DHPMmkJehNV/R3wFeAmr+wJwB3AfBE5xnfq+4GfpbqeiLQD7wRe8R3eDVwENAEfBL4pIiepai/wFmBHjFX1d8ClwFnADOAA8J0Et/wF8F7f/gXAXlV9CvgA0AzMBtpxz6g/zjMYAp4A3uQdehPwMPBIzLGwVXEjsM2r27uAr4jIOb5LXgLcArQAK33PphYnpIPAn+P+vr8BngFmAucCnxaRC1JdKx4i0gBcBjwtImUZXPt/gTrgWGAK8E3vuicCPwY+inuO3wfuEJFq37X+HLgQmA8cD1ye5O87Cvw90AGc7tXtb7x7dXh1utK713pgue87XoJ7uXkn0In7O/0i2XMxAFW1pcQXYBPQAxz0lttxAjAI1PrOey9wv7d9ObAl5jqXA4/EHLsB+LK3vQLYFnPf87zta4D/iyn7PeBab/tYXINdneA7PAD0AYcABdYCc5J859uBT8Wrl3fsReBc3/50YBioiHOtI4BuoM7bXwl8wdv+EPAocHyAv8M1wG3e9jPAIlzj5z/2AZzwjAKNvrL/Btzgu85Dca59B/Ag8N+AeMdPjfN3vBL4SaJrxan3DcCA99t53bvPwnSv7T3jENAa5x7fA74Uc2w9cJbvt/Q+32dfB65L9PeNc/1P+57zX+FeesKfCbAV+Ii3fzfwYd/nZd5vb24u/j8nymKWxcThUlVt8ZZLgbm4bpGdnql+EPc2N8VXZmuO6/RT4C9FRHBWxc2qOpjk/E+qajPurbIV138OgIi8RUQe97ptDgJvxb1VJmIucJvvu7+Ia6DHdCGp6ive528XkTrgYlxXDLg35d8DN3pdK18XkcoE93wIeKPX3dWpqi/jhGa5d+w475wZwH5V7faV3Yx7ew8T729zGu7ZfFW9Vs77njPC39P7rv8c8z2D/J2/4f12pqnqxar6agbXnu19rwNxrj8X+IeYa83GPYswr/u2+3B+q7iIyJEicqeIvO51gX2FyO9hhr9e3rPyO8jnAt/y1WM/TlD8z9+IwRxSE5etOMuiQ1VHEpwTm3J4PCmIx5RV1cdFZAjXV/+X3pL6QqrPifOTfEdETgKqgFtxb4y/VtVhry9cktR7K/AhVV0VsP7hrqgyYJ0nIKjqMPCvwL+KyDzgLtwb8Y/iXOMxXJfVXwOrvPJdIrLDO7ZDVV8TkRGgTUQafYIxB9jufwxxrv8H4FngjyKyQlV3ed/zNVVdlOS7Zfp3TffaW3Hfq0Wd3yn2Wteq6rUZ1CNe/b8HPA28V1W7ReTTuO48gJ1Ev2iIf99Xl6RdckY0ZllMUFR1J65x+Q8RaRLn8F0oImclKbYLmOV3FKbBLmCe18/t52fAt4FhVX1kbLGE/BT3BnsxTiyqgT3AiIi8Bed/8d+7XUSafceuA64NOy5FpNPrq07Ejd41P07EqkBEzhaRN4gLDOjCdWWF4l1AVfuB1cBncP3gYR7xjj3knbcVZ3H8m+fEPR74MJAy9FhVv+7V749e3/yTQLeIfE5EakWkXESOE5FTUl0rAGld2/vN3Q18V0RaxTniw/6aHwAfE5FTxVEvIm8TkcYA9Yj3923E/T16xIX5ftz32W+BN4jIpeIitD4BTPN9fh1wpYgcC4cDQd4doB6TGhOLic1f4RradTh/wS24fuVE3Ae8ALwuInvTvNcvvfU+EXnKd/x/cd0vaY3BUOcw/hbwL97b9yeBm3Hf4y9x/erhc1/CWQYbva6FGV7ZO4A/iEg38DiuDz7R/XbiLIPluMiwMNNwz60L11X1oPedEvEgrqvPL4wPe8f8IbPvBeYBO4DbgKtV9d4k1/XX9Us4n829OEvmIlzE1WvAXuCH3vFxoaqjGVz7/ThBfQkXlPBp71qrcdbVt3F/w1dIEZnlq0e8v+9ncb+DbpwQ3eQ7fy/wbpzfYx+wGCfig97ntwFfw3UtdgHP45zoRhLCTjLDyAle9M5u4CSvD98w8opn7W4DLlPV+wtdn1LFLAsj13wc+JMJhZFPROQCEWnxQnP/GefferzA1SppzMFt5AwR2YT7J720sDUxJiGn43w74W7YSz2fkpEh1g1lGIZhpMS6oQzDMIyUTKhuqI6ODp03b16hq2EYhlEyrFmzZq+qdqY6b0KJxbx581i9enWhq2EYhlEyiMjmIOdZN5RhGIaREhMLwzAMIyUmFoZhGEZKTCwMwzCMlJhYGIZhGCmZ9GKxciXMmwdlZW690pIWG4ZhjGFChc6my8qVcMUV0Nfn9jdvdvsAl11WuHoZhmEUG5PasrjqqohQhOnrc8cNwzCMCJNaLLZsSe+4YRjGZGVSi8WcOekdNwzDmKxMarG49lqoq4s+VlfnjhuGYRgRJrVYXHYZXH89zJ0LIm59/fXm3DYMw4hlUkdDgRMGEwfDMEoaVffGm0MmvVgYhmGUDMPd0LUeul7yFm8bhbc9n9Nbm1gYhmEUExqCvm1jBaHrJejfETlPyqFhITQdBc3H5ty6MLEwDMMoBCN90L0BDr0E3X5rYQOM+gaAVTZD09Ew7Xy3bjraCUTDQiivylt1TSwMwzByhSr073Qi0L3eCUNYFPr8A7oEGuZD41Ew5WxoPtptNx0NNVNy7o8IgomFYRjGeBkdgO5XxnYbda2Hke7IeRUNziqYcma0ldC4CMprClf/AJhYGIZhBEEVBvfEEYSXoHeT8zWEqZvjRGDB5RFBaDoaamcUhZWQCSYWhmEYfkLD0P1qpOuo66WIX2HoQOS88lpoPBLaToF5748IQtORUFFfuPrnCBMLwzAmJ4P7x1oJ3eudUOhI5LzaGU4I5r7HiUHjUc6nUDcbZPKMazaxMAxj4hIacV1Esd1GXetdl1KYsirnN2g+Dma/y2clHAWVTQWrfjFhYmEYRunTuxW2/do5iXtfiwhC98sQGoqcVzPFWQazLo32JdTPg7LyQtW+JMi5WIhIObAa2K6qF4nISmApMAw8CXxUVYfjlBsFnvN2t6jqxbmuq2EYRUxoBPY84kRh2+3OYoiHVEDjQicCMy+KhKA2HQXVbfms8YQiH5bFp4AXgbAttxJ4n7f9c+AjwPfilOtX1SU5r51hGMXFwG7Y/hvYejvsuDNYmapWZy0c8VFoOwnKKnNZw0lJTsVCRGYBbwOuBT4DoKp3+T5/EpiVyzoYhlGEaAj2PelZCb+GrheDlWs7BWZd4oSheXHJhqGWIrm2LP4L+CegMfYDEakE3o+zPOJRIyKrgRHgq6p6e7yTROQK4AqAOTZrkWEUF0MHYPtdsN3rOgqN6XEeS3mtE4NZl8D0C6GqOde1NAKQM7EQkYuA3aq6RkRWxDnlu8BDqvpwgkvMVdXtIrIAuE9EnlPVV2NPUtXrgesBli5dqtmpvWEYgVGFg886Mdj2azjwdLByLW+AmZc4UWg72ayEIIwOQu9m6HkVeja6MN/ejc5SO+uOnN46l5bFGcDFIvJWoAZoEpH/U9X3icjVQCfw0USFVXW7t94oIg8AJwJjxMIwjDwx3AM7fx9xMPvTWCREIt1GM94GNR05rmSJowpD+50I9Gx0QhDe7nnVZaPF905cXgsNC5wDP8fkTCxU9UrgSgDPsvisJxQfAS4AzlX1j4+PICKtQJ+qDopIB054vp6ruhqG4aNrfUQQ9j4WrEzjoogotJ9mYajJCA1D39ZoEejZGNke7oo+v2aqyzA75Sy3bljglsaFUDMtbxZZIcZZXAdsBh4T9yV/papfFJGlwMdU9SPAMcD3RSSEm/r1q6q6rgB1NYyJyegAvP7HiCj4B6glY/qFThBmvh3qZuSyhqXN0KEYIfAJQu9m0NHIuWVVLuNs/QLoWO5EoGGBJwzziyZ1iKhOnG7+pUuX6urVqwtdDcMoHno3RwRh1/3BytTNjlgJU95kYajxCI1C//ZoEfBbCkP7o8+vbvdZBT7roGGhSydSQEtMRNao6tJU59kIbsModULDsPuhiCj0bQ1WbsoKL+roYvcGa0Qz3ONGg8frLurdFD0yXCqgfq4TgDnvjghC40Konz8hIrpMLAyjVOh/Hbbf4Qar7bw7WJnqTs9KuASmngsVtTmtYkmhIfdMY30G4fXA7ujzK5udCLQcD7PfEW0d1M2GsondnE7sb2cYpYaGYO/jkTDU7g3ByrWf5huslvvImJJhpN9ZAf5Q03CUUc9G57sJI2Wu0W9Y4Hwysd1GVa2TOrzXxMIwCsHgPtj+WycK238dPXFOIioafIPVLoDKMWNdJx+qcOgFeP0e2HmPG7sxsCtiHfTviD6/ot41/o1HwvS3RFsH9XPzOqd1qWFiYRi5QtUNUAtbCQefDVaudYkbrDb7Umg5YVK/zQLOd7D7IScIr9/jxCERO+92DuOGhTDt/GjfQcMC1y032Z9nhphYGMZ4Ge6CHb+LiMJoX+oyZZWR0csz3jq5s6GqOivg9XsjFkKgAX8eDUfAtPNg+vlubfNP5AQTC8MIgqpLdhcWhH1PBivXdLRvsNqySTWzWhSjA7Dn0Yh1sH9NeuWnnu0shWnnQ+uJNuivAJhYGIafkX7XmG37tfMlDO4LVm7GRU4UZr4daqfmto7FSt82Zx3s9AQh6EA/gNqZnmVwPkw9B2qn5a6eRkaYWBiTk56NkXEJux8KVqZ+XsRK6HzjhA+VHENoxFlUYetgz6r0ynecHrEO2peZM7nEmGS/dmNSMToEux+IzJnQvz1YuWnnef6Ei6F+kqW9H9jj0oCEBSHoAD9wo5Sn+nwH9XNzV8/JyOigs976tkaW3q3QtwUQWBFwoqgMMbEwSp++7W6w2rZfu6yoQaiZFrESpp4N5dU5rWLRoCE4sDbiSN71x/TKt57oLIPp50PHGTbIL1uERmFgZ6TxPywEvmVg19hy1e1ubEjjopxX0cTCKA1Co7B3VcRK6AmYrb7zjZ4v4RJoyv0/VFEwdMjlgQpbB90vBy9bUe+sgnB3UeMiCzUdL6rOfxNPAHo9YejfEZ1cENy4mrrZbmldEtmunx3ZrqjL29cwsTCKi0MvwpZb4MAaJwpBqGyJWAnTzy+aLJ05IxyZ5XcmhwaDl286JmIdTHmThZqOl6FDYxt/fzdR/7bokeLgMs2GG/wpK3wCMCeyXdlcVEJtYmHkn9AovHIdrP7b9Mq1neyNYL4Umo8tqn+krDPSC7sfjlgHB58LXlbKo62DluMmb8jueBnpj+MjiOkqih0TImVuYGDdbGg7CeovjQhDeKnpLLm/iYmFkTt6N8Of/hZ2ZOB4W/4LmPGWCZGtMyE9G6Otg+FDwcvWz/eFmp7t+q6N9AgNu+6fZH6Cwb1jy9VM8fwER7rkjIe7h+a4de30CRkpN/G+kZFfVGHTz+GJD7p/vnQ55buw8IqJOchqdNDNNBd2Ju//U3rlp5wVsQ7aTpqQDVDO0JBzCCfyEfRthf6dRE1RCq7rJ9z4ty+L4yeYBeU1BflKhcZ+fUYwBnbDU/8Am/4v/bJT3gSnfA+aF2e/XoWmb0ckTcXr98SPWElE7fSIGEw71+0bqQmnB9mzCvY+6kaGH3refda4yI0H6d829uWlvDbS+E9/s69byO8nsOSMiTCxMKLZfpezEmJz+Qfh+C/DMZ+dWGGooRHYvzrSVbTn4fTKt58acSa3n2YD0YLQv8uJwN5HPUEIOA84OLGecVF0xFB4qW6f2H6uHGNiMRkZ7oJnroIN306/bMsbYNkPoOPU7NerUAzshV33RayD3s3By1a1+pzJ59mMc6kY7oZ9TzgR2OMJwkhP+tepm+3mq+48AzqXuwmJbPrXnJJzsRCRcmA1sF1VLxKR+cCNQDuwBni/qg7FKXcl8GFgFPikqgYcbWUcpnerb/7lNAdfHfNZOO5qqGzISdXyioZcenC/Mzm2rzoZLSdEnMmdb8xrbHtJMTrkUrKHu4b2rvL8AmlS2eIEICwG7adM/HDoEiAflsWngBeBcDD314BvquqNInIdThC+5y8gIouB9wDHAjOAe0XkSNXYUSsGoRHY84iXDfX29N6K62bBqT92DWGpM9wFux6IWAdd64OXLa+NDjVtOsq6K2LRkHume1Y5EdjzaPBZ/PxImRv53bncrTtOc2GkRtGTU7EQkVnA24Brgc+IiADnAH/pnfJT4BpixAK4BLhRVQeB10TkFWAZkEbn5QSjfxds/40ThB2/DVamuj0yZ8K080r7jVjVNVZ+Z/Jof/DyTUdFxGDKWRM7JDcTerf6LIJHnZ8mE1qXOIsgbBXUzzXhnSDk2rL4L+CfgHCIQTtwUFVHvP1twMw45WYCj/v2E503sdCQy+oZnjOh66Vg5dqXRabbbDqmdP85B/fDC19xIaZDh+DgM2kUloh1MP1814ddYoOecsbQAdjzWMQi2PsohMb0/KamYWG0n6Bp8cQMeS41Rgfc3zjH0XQ5EwsRuQjYraprRGRFDu9zBXAFwJw5JZIhdOiAN/+yN2dCkPEJFfW+mdUuLN0UDbsehLWfc07OdKmfGxGEqedY9wW4Ecb7V0dbBfEGkqWiZkq0RdB20qQdT1AUhEbd33Hgdeh/3a3924fXO91gztqZ8I5tOa1SLi2LM4CLReStQA3OZ/EtoEVEKjzrYhYQL2/0dmC2bz/Reajq9cD1AEuXLk3Da5ljVN2b8dbbnSAcWBusXMsJXp6jS1yGz1KzEkZ64aVvwrP/kvk1Wk90g/Xalk7ugWihUTd+YM+qyJiC3k3pX6e8NiICHctdJFtVS7Zra6RC1aUG6fca+WRCMLjb9TTEUtHgMibXToPm49zLU800qMt9x0vO/hNV9UrgSgDPsvisql4mIr8E3oWLiPoAEC9b3B3Az0XkP3EO7kVAwHks88xwD+z8XSQbapC5g6U8kgl15ttKL1XDgbWw9vPB04HHY+rZcMJXoWNZ1qpVUqi6dB9+i+Dgs5ldq32ZTwxOz0vDYfgYHXTjO5JaAN46np9NKqBmqhOA2pnuJSksCP51zdSCRicW4rXtc8CNIvJl4GngRwAicjGwVFW/oKoviMjNwDpgBPhEwSOhDr3kLIRtvw4+SKjxSN/8y6eWTv/u6BC8cj0883lnKWTKcVfDMZ8p3S6z8TCwOxI+GhaDTGg6JhI51Lnc/aZKzdosRTTkptQNN/TJLIGhA/GvUd3uNfLT3N8urgBMg+q2kvCviWrx9NyMl6VLl+rq1RlGcYBzFL3+x8jYhKBzCM94q2/+5RJJ2dD9Cjzz/2DLTZlfo/VEOPHrzhSeTAz3eAPLfKOMg1iUsdTNivYTtJ5gA8tyiaobABjEAhjYNXZ+CXBderXTYxr+2P1pUD2lZEbri8gaVV2a6rxJ3CHs44G3wY67kp9TPzfiYJ5yZvH/U6u6tNb+UNNMjLMjPwnHXeUcoJOB0DDsf9qXauJRl5k0XSqboyOH2k6ZGAMci5GRXvdbP7DWvc0PHfI1/DujhWC0b2x5KXddPOGGvnVJfAugdprzGUxSy87EAtwPIMzUczwr4WJomFewKgViuBt2PxgZldz1YvrXqJ/vrIPZ7ywJU3hchAeW+UcYpzN4L4yURVsEHadbZFa2CY26Gf4OrIWDa936wNr0EjVWtUYa+fZT41sANdO8nFET/LefBVKKhYjUAf8AzFHVvxaRRcBRqprb2cHzyRtvAsbRHZMrVF13UdgyeP2e9HwIjYt8oaZnT/wImL7t0ZFDmQ4sazkh2k9QP2/Svk1mnYHdkYY/vGTykuNHyp010LoE5vw5NB3tLIWJlNCyCAhiWfwEl8PpdG9/O/BLYOKIRSEZHXDpOsJ5iw48lV75qec6QZj+ZvfPMlHfkIYOwN7Ho/0E6UwlGqZhQXQYafOxpRN4UKyM9LtuIL8FcGBteiPs49GwwPnFwkLQusRFC5lwF4QgYrFQVf9CRN4LoKp9XtoOIyi9W6J9B4P7gpetm+3LW3TuxPQdDB1y06y++I3MBpSFqe6MtgjaTraBZZmiIRfaG2sF9Mcd7hScqlbX6LcsiQhA09El4wyezAQRiyERqcVL0ykiC4EMXukmMKFh2PtERBDSDZPsPCOSt6j9lOJ3nqdDaBg23wgv/nt680jHUl4TZ2BZa/bqOVkY3Oc1/E9HBODQC+O/bssJ0HaiE4G2E126lYne7TnJCCIWVwO/A2aLyErcyOzLc1mpoqR/l0vzHZ4iM503rOoO34xo57mJWSYCqrDrficEO3+XnWvOeTcsvtI1OEYwRgddgx9rBWQSzuunfu5YK8ASA05aUoqFqt4jIk8BpwECfEpVx9FXUKSERt3bVtg62HVfeuXbTo50F3WeMTG6Pw6tc11DG3+Snet1vtHNkzHz7RPXt5ItVF26eb8FcOBpN3f0eKhojLYAWpe4gX/mDDZSECQa6iRvMzyLyRwRaQY2+7LHljZ3LIKeV5KfU9EQyWg67XyXgbOU37D6d8GG/3FWQSYZSGOpn++EYMHlpZ0KPdcMHYADz0RbAGll101AyxuiLYDWE0ovjYwxFg25RIGD+yLLUJztsipY/r85rUqQbqjvAicBz+Isi+OAF4BmEfm4qv4hh/XLD3PfAy982UXGhK2DKW8q3cnbQ8OuEfJHDo3HMVlWBcf8Exz5CRebbkQTGoZDL0ZbAAfWwvDB8V23dqaLBmrzRQTVzzOrrFQZHfI19HsTN/z+7aH98RMKgvsdVLVCVbv7XeSYIGKxA/iwqr4Ah2ex+yJunopfAaUvFid8yS2lQHgSIH/OoaDzXiRiwQfh6M9Ay3HZqeNEQNV1+cT6AXpfG991K+rH+gGaj4WK2vFd18gfqm5mRn/jHqThTzbXeHmtswSr2t265fjItv+4f7uqJa8vDkHE4siwUACo6joROVpVN1oEbQ7o2x4ZYbxnlZsIKBNajo9ON1E/v7S7zbLFcBcceDZmZPDTid/egtJ0TLQV0HKCjeouBULDbtKtuA19orf//ZCwB15cIx5u0GunuZeB6gQNf3WH2y+Bl4UgYvGCiHwPl1Ic4C+AdSJSDQSYtcc4zNBBb2CZN8J476NuUF661M+PiEDHcpfXfjIPLAuNOOsqyg+wNr3xLPGonR7jB1jifFWT+VkXK6ou/9NIn+v+C/rGP9yV+JplVdENevPixG/54e2q1gn7+wgiFpcDfwN82ttfBXwWJxRn56RWpcjoAOxfE+0nCJq11k91h2cReIPL2k4uibeOrKPq0kLH5gbqfnl81y2viQhAOCqo5ThzyhcTo4NuQGD3Buja4Nbh7YHXM7tmZbOvce9wc7InavTD+xX1Zo37CBI62w/8h7fEkqQTbgIRGnVx7H4/Qc/G9K9TVh0ZVNa5HDpOm3wDywZ2w6aVsPGGzCf7iUfTUWOtAHPGF56BvdGNfff6iABkIwrPT80UOOpTrtsnSghaJ9ZA1wIRJHR2EfBvwGLc9KgAqOqCHNYrvwwdgO13RSyCTEMZ25b6hGD5xBl8l4rQsJtT/LUb3Fwg2aJmSowAnOiSI05QM7+oCY1Az2sxDb+39OVg7ufGI93SFLOunWFv+wUiaCLBq4Fv4rqdPghMrNi9W9pSn9N0VCTnUMdytz/RQxgPPu8G5G28wYXwZZvmY924jHmXlc6kUROBoUPx3/S7N4xvZsR4VLZEGvrGI93/TdOR0HCEze9RYgQRi1pV/aOIiKpuBq4RkTXAF3Jct/yx4i549ccRP0Hrkomb2GzoELz2v84K2L8m+9cvr4H5lzsRaF9mb4G5JDTqwnu71o994+/dlP37NSyI/8ZfO8usvUlAELEYFJEy4GUR+VtcivKJ9Uow4y1uKVXiZgh9OrMZ3hIx/QInArMumZwO91wz3OOc9/GcuuMd3BdLRUN0g394e5El/zMSEkQsPgXUAZ8EvoTrivqrXFbK8BjYO3aOgGxkCA3TsNBZAPP/CurnZO+6kxlVN1q+K07f/ngjueJRNzvmTf8ot66fC2U2EaaRPYL8muap6p9wkU8fBBCRdwNPJCskIjXAQ0C1d59bVPVqEXkYCOfRmAI8qaqXxik/CoRzWm9R1YsD1LX4icoQ6ksSl2x0ZxDq542dKKZutnUDjYeRfpczLPZNv3vD+ObdiEd5zdgunvC25XgyioAgYnElbma8VMdiGQTOUdUeEakEHhGRu1X1zPAJInIrkCh8pl9VlwSoX+FRdWkgYlNDjDdDaGVzdONvGUIzQ9WF7B5u8NdHN/w6mt371UzzGvyjohv+hvn2tzOCoeqCDYa7IstIl/M5xh4b7nIDCJf+T06rlFAsROQtwFuBmSLy376PmoCU2WZVVYmMw6j0FvVdvwk4B89aKUoG948dFTyeCXzCtLwh2gpoOQGqA0RkGS4ZW3jAVmxET6YDthIh5dFdO/6Gv2aKWW3GWDQ0tpEfjmngUx73RCBICpryOqhsyks3cjLLYgewGrgYNwd3mG7g74NcXETKvbJHAN9RVX/X1aXAH1U10Xj7GhFZjROmr6rq7QnucQVwBcCcORk+sJe+BU99OrOyYepmj7UCLENocrpehu2/gR13ukmUckl1R5wunqOc38Yc9oaGXFdwuLEOv8GPxDTiQ4fGHotq/LvxvRMnpqLeNfKVTVDRBFXNbhBpeD/8WVVz9H7U8ca8+qXEGQBJThCpVNVx5YASkRbgNuDvVPV579jdwA9V9dYEZWaq6nYRWQDcB5yrqq8mu8/SpUt19erV6VfwljY3MC8WyxAajNFB2PWAa/S335mbsE0/jYsShHDOtLf9yUZo2EX99W51gwNrpriR4em+2QedVbCiwWuwm8c24IeXRJ95xysaiir4QETWqOrSVOcFqfEyEbkGmOudL7hepsAjuFX1oIjcD1wIPC8iHcAy4B1Jymz31htF5AHgRCCpWGTMn+2zRiZM3zbX4G+/E3b8Nn/3LauEGRfBzItgxtugdmr+7m3kn9FBFzXWt81bto7dHtiVvftVNLq3cf+be92s9Br+ioZJPZ4kiFj8CNfttAYI7AkUkU5g2BOKWuB84Gvex+8C7lTVuClXRaQV6FPVQU9YzgC+HvTeaTMRhUJDkQFb/mienb/P/b0bj3SN/syL3CDHiTrAcTIy0u9r5OM08H3bMkugmTHiGv3wMvvPXNiwv8GvaLDu4CwQRCwOqerdGVx7OvBTz29RBtysqnd6n70H+Kr/ZBFZCnxMVT8CHAN8X0RCXtmvquq6DOowMRjpdTH6sbH7XeuzP2ArlukXuDmzZ7wNGubl9l5G7hjpS97A923NTUqXREh5pIGvneXyqPnXdbOgZuqkfpMvNoL4LL4KlONmxRsMH1fVp3JbtfTJ2GeRL1Rd/2pUg+976882dbOinbmNR7qUDfVzze9SKgx3J2jcffu5fmHwU1bpgjnCjXzdrMh+eLum097kS4hs+ixO9db+iyku7HXyMjoA3a/GD+HMthleVh0nNYO3VLdPzG60UiY87WaiN/n+bc4hG9Spmg3Ka3yNe5wGvm6Wixiz35KRgCDzWUz8CY5G+mD/U2MzcHZtSDJ9YoYcHrAV0/A3LLABW4VG1b2l98Y06v0xjX22M7Mmo7wuceMeXqrarJE3ck6Q+SymAl8BZqjqW0RkMXC6qv4o57XLFzfXp19GyhKnZ6iZZv+8+UTVTZM5pnGPebMf7c9fnSoakjTw3nZls/1OjJIhSDfUDbg5La7y9jcAN+GipCYGb/wlvPgfXq5932jdhoU23WYu0RAcWgd7H3Nzk+973O2X10H7KZGGPtszqiWjsjl5Ax8OtzSMSUYQsehQ1ZtF5EoAVR3xkvxNHOa8yy1GMEIjLu3Jvsdhz2Ouse95JXvXH+2D3Q+mV6aqNXHjHu6rt8l2DCNjgohFr4i0441hF5HTgEM5rZWRG0KjLuHh9t+6hn7vY9C7udC1iqaiHhZ8CGa/w2vkZ5p1ZxhFQBCx+AxwB7BQRFYBnbhBdUa+CI1A/86xoZOxjtdCUtkMHadHlvZTbCIdw5hABImGekpEzgKOwqX6WD/eXFGThtAw9G2P07iHG/itTgQKSXWH18Cf5tZtS6GyMXU5wzAmFUGioT4BrFTVF7z9VhF5r6p+N+e1KxRj8tbENPDZzlsThNqZvr74mNDJuplQO8MNmDIMw8gBQbqh/lpVvxPeUdUDIvLXwMQRi3veBHsezsGFJUkDHx7tOm1cKQ1WroSrroItW2DOHLj2Wrjssix+BcMwDIKJRbmIiDeZUXiOiomVGa7p6GixkPLkDXzdbKjuLHjempUr4YoroK/P7W/e7PbBBMMwjOwSJDfUN4A5wPe9Qx8FtqrqP+S4bmlT9Lmhssy8eU4gYpk7FzZtyndtDMMoRbKZG+ofcQLxcW//HuCH46ibkSW2bEnvuGEYRqYkFQuvy+kFVT0auC4/VTKCMmdOfMsi09llDcMwEpE0j7CqjgLrRcSanyLk2muhLma8Wl2dO24YhpFNgnRDtQIviMiTwOF0m6p6cc5qZQQi7MS2aCjDMHJNELH4l5zXwsiYyy4zcTAMI/cEGcH9oIjMBRap6r0iUoebOc8wDMOYJKSc+9AbgHcLkdDZmcDtOayTYRiGUWQEmSj3E8AZQBeAqr4MTMllpYzcsHKlG5tRVubWK1cWukaGYZQKQcRiUFUPzz4jIhV46cqTISI1IvKkiDwjIi+IyL96x28QkddEZK23LElQ/gMi8rK3fCDg9zESEB7tvXmzm1guPNrbBMMwjCAEEYsHReQqoFZEzgd+CfwmQLlB4BxVPQFYAlzozYUB8I+qusRb1sYWFJE24GrgVGAZcLWItAa4p5GAq66KpAUJ09fnjhuGYaQiiFh8HtgNPIcbyX0X8P9SFVJHj7db6S0pLRKPC4B7VHW/qh7AjRq/MGBZIw422tswjPGQUCxEZIqI/Bdu4qMFwIdV9V2q+gNNlVAqco1yEVmLE5t7VPUJ76NrReRZEfmmiFTHKToT2Orb3+Ydi3ePK0RktYis3rNnT5BqTUoSjeq20d6GYQQhmWXxM9wgvP8BGoD/TvfiqjqqqkuAWcAyETkOuBI4GjgFaAM+l+51Y+5xvaouVdWlnZ2d47nUhMZGexuGMR6SicV0Vb1KVX+vqn8HHJ/pTVT1IHA/cKGq7vS6qAaBn+B8ErFsB2b79md5x4wMuewyuP56l5FWxK2vv94G9BmGEYykPgtvVrw2z+FcHrOfFBHpFJEWb7sWOB94SUSme8cEuBR4Pk7x3wNv9u7XCrzZO2aMg8suc6nLQyG3NqEwDCMoyUZwNwNrcPNuh3nKWyvOj5GM6cBPvcy1ZcDNqnqniNwnIp3eddcCHwMQkaXAx1T1I6q6X0S+BPzJu9YXVXV/Gt/LMAzDyCIpJz8qJSbb5Ef5wKZtNYyJTTYnPzImKTZtq2EYYYKMszAmKTaQzzCMMCYWRkJsIJ9hGGFSRUOVi8hL+aqMUVzYQD7DMMLYtKpGQmwgn2EYYWxaVSMhNm2rYRhhbFpVIyk2bathGGDTqhqGYRgBSCkW3rSqV+CS/i3EZX+9Djg3t1XLI3efCAfWZv+6ZVVQXuuWirr42+V1UFHr20/2uXe8Is52WZVL+mQYhpEDgnRDfQKX7O8JcNOqisjEmlZ16rm5EYvQkFuGD2X/2qVKVZtbqtvdEt6uaofqNrduWgQ1000IDaOICCIWg6o6JN4/a9BpVUuKk77hlmyi6oRitA9G+mG0f+z2aL+3722P9sNIgO0xx/ogNJzd+ueKof1u6Xml0DVJTCCLMB2L0SxCo/QJIhYPisg/E5lW9W8INq3q5EYEyqvdUjXBZoTVEAx3w9A+GNwHg/sj20P7fev9MLg3IhBDB4Lfo2YqjA44MQwNpT4/m0xki9C6Ro0MCSIWnwc+jG9aVVX9QU5rZRQ3UgZVzW5pSJV8uMTItkWY6nMTwuxRVgWLPg51s0AqoawSyioi21LhHfNvV6Rxrm9byiedEAYRi2tU9QvAD+DwqO6VqmoBlcbEY0JbhJNACNd/K3/3SyUoUeLiiVGgz+NsxxM0/3ZFPcx+R06/bhCxmC0iV6rqv4lIFXAzbh4KwzBKickghDrqltAw6Ihbj2dbhyE0EvDzONvqnR+13R/ZjnvNOMdSUTO1KMTiQ8BKEbkSOBu4W1W/mdNaGYZhpENYCCciqp4IJhG2PMxLlFAsROQk3+63gO8Dq3AO75NU9an4JUuQ3Y/Aqz+A6k6o6XTr6o7o/cqmSddHaRhGESDiuquogPKaglUjmWXxHzH7B4DF3nEFzslVpfLOvWfm5rrV7Z7weOJzWIjCItQRvV3AH0IxYLPyGUbxklAsVPVsESkD3q2qN+WxTvnn0u3w+h9gYA8MesvAHhf2Gd4e6U7/uoNeOCk5yvJeVh1AhPyWUpuLZCpCbFY+wyhuUs7BLSKrg8zPWgxkPAd3/+uwfzXUTncjh2umuEiD8RAa9cYa7PGJ0N44guT7rFQG1gHUzoCmY6D5GGheDE2L3bqmM6PLzZvnBCKWuXNh06Zx1dQwjCRkcw7ue0Xks8BNRKco35+iAjXAQ0C1d59bVPVqEVkJLAWGgSeBj6rqmFZSREZxYzsAtuQ0Jfpt0zMvW9XmRCYsNLUxS810aDsZKhuyV98wI30+62dvfKvIL0rpDIpLRf8Ot+z6Y1Yut+krke2dB6Zx3X0fY09XJ/t6OmCX30JqH7+QG4aRNkEsi9fiHFZVTToaS1x+kHpV7RGRSuAR4FO4hIR3e6f9HHhIVb8Xp3yPqqbVwmZsWex+BNZ9Ffp3wsBOty4UZdVjxSZKgGa4dXVH7ruUQqPQtwUOvQCHXoSuF+HQOrce7srtvbNJRX1MN10KH5IFMxiTiKxZFqo6P5MKqFOhHm+30ltUVe/yVfJJYFYm188qrUvg5G+5kZ/phN+puq6m/p2RZWAn9O2IiE54Ge0Lds3QIPRucku2qO6MCM3Qftj3JDQdBa0nQdtJkXVVS3S5snJomO+WmRdlrz5+Rnqhaz2r7n6RVXetY9GUdRzobWXb/llMa93LBSv2MHdqjMWUbmqykV63ZPOZxhIWmkA+pI6JG+ZpTFiCWBaVwMeBN3mHHgC+H6/rKE7ZcmANcATwHVX9XMx1nwA+paoPxyk7ghv8NwJ8VVVvT3CPK3Ap1JkzZ87Jm+N1fKfi52m+RdbNjiz1s6Fujm97tmsQMn0zHemDgdd9QrNjrBj17/QazSKiqs0nPCe77YYFaVk/OYmGUoWRngRddQn8SJkEM+SasurggQw1nW7QXZEGMxjFRVDLIohY/BBnFfzUO/R+YFRVP5JGZVqA24C/U9XnvWM/AHpV9dMJysxU1e0isgC4DzhXVV9Ndp+Mu6G23g5P/wP0bc2fk7myKVp06mZD/ZxoEcpGKG1o1DWCYbHZ+xi89A2XpK9YqWiEo/8+TlfcNJfaoNgIHMzgE6tiDGaobI4Wn3gi5D9eUZf6mkbRk02xeEZVT0h1LECFvgD0qeo3RORq4ETgnaoaClD2BuBOVb0l2XkZi0U6hIbd237vVicu4aV3S2Q7n2/9tTPjCI1vu2ZKdvvfVZ3oHHgK9q+B/U+57b5t2btHNqhsTh54EPb9VDSWhn/icDBDioi6XAQzZAspH2sVxRWn8GcWzJAPshkNNSoiC8Nv9d6b/miACnQCw6p6UERqgfOBr4nIR4ALcJZCXKEQkVacsAyKSAdwBvD1AHXNjDsWQs/GxJ/XznBdKg0LoN7rw29YAFPOdJ9lYu4PHXLO42SiEyQRW/92t+x7PP06JELKoWM5dC731me4f1xwDWvdDLdky48x0gcHn/ME6KnI+JFwF5zf/xPUXzF8yC1dWRrjIhURgUkmQtVTnK8n21TUQcUc9yKQCzQEQwejxxYdFqQE3Xej/WneY9R1sQ68npOvAMCiT0DjIu951Xvp1P3b9V66dW/b0qgHJohlcS7wE2AjIMBc4IOqen+Kcsfjuq7KgTLgZlX9oueL2AyEO4Z/5R1fCnxMVT8iIstx6UVCXtn/UtUfpfoyGVsWz30JnvtC+uWCUNkSEZqws7je266fOz5HZ2jENaBRouOJTXh/cE/Wvkra1M91YhMWnpbj8/OmqOrerGOFJtbv07/T+TMKRXX7WMGpme6E2H98onT3jA7FD+lO1mWXa6QMymMEJJm4xDuWTJjK63Lz8pBFxt0NJSKfBh4FnsI1+Ed5H61X1cEs1TOr5KQbKjTqdTu9Bj2vOQukZ2Nkv39Hdu/np6wqvkUTFp7Kpuzcp3cr7H0U9qxy6/1rsnPd8TDtPBc44O9SC/tyKurzX5+RfhjYFSM2cYIPBnbnv25hymsi1k88ETps/bRPTOd3VAr2PhcBN+qtR/qitxN9luj80d5I+vV0KatOLi7lKQQntmzs+eU147KOsiEW3wCWA0fjBsetwonHo6kG5BWKjMXiiStcIsEwDQug8Ui3NPnWdbPT+ycLh9b2bHTC0usTm/B+apdN5tTNiQhLvSc0dTNcpEzL8dltMEYH4cDTsOdR2LvKrXPZ3ZCKmmnxhSYcuVY7rbANpobc23Mii8d/rJDBCDVTk4/3qZ3unvVkCQXWUGTejsPiElRoAopV2sEP4n7Tl2YQCUp2HdxVuBHXy4HTveWgqi7OqGY5JGOxuOdM2PPI+G5e2TRWYBoXue1MLYCRXujZ5BOZ16Ktmnx2obSd4t72p50DHWe4qTNzQd8O1302dNDny4nx7WTydpcJ5bXxhca/n4uR+Zky3OMLu04Qct2/073AFIqKhhihiRd8MN11305WX0JoOIm4xAhN+FhZJRz3/zK6XTbFohknEGd46xbgOVX9YEY1yyFZ6YYKDbsGunuDW7o2RLZzEfFTPy9aWA5bMXPH19cZGnb1jRKYjbD5xqxVPTD1853QTD3HiU3NlNzeL+Q5Ug8HDcQRnXxaPTVTk4dI10wvzn7t0IjrVkvl9+nf6eZUKARSFi04s//M+coqGqCy0UW7VTa4/YnY9ZYFstENdT1wLM4R/QTwOPC4qhZhTJ4jY7F45ip44Ssu4qV5cXRivOZjXEOeKr5/cD90vzxWYLo2BB+9HZSK+jhWjLcdOwo7EzQEB593eZ9evw923Zv/rpCp5/j8Mz6fTXVH/t44h3tiItXiBBFk+2+biLLq+EJT51k49bOz58PKFaouTYw/00H/juhBqGERykU6mfI6T0AaIuvDYuI7nuwz/3qCdL1lQyx+B3QAz+N8FY8Bz2sqU6SAZCwWdx6TeYhl4yJPXI7xCc3RwZywoRHo3RwjMJ7g9GbW/5iUutleSGmXs2hmXgQz3gZTV2R3Lo2+bbDrfth1H7x+b37HYNRMi/bR+KPQamfl/w1eQ84xHs+6CYtOPnORVXcm6Vab7bqISmlsw+hgJPCgf6d7mdBhGO523bTD3W5E/nCPWx8+5lvHfh7Uj1hW6ROVACIUb+0vW1FfkK63rHRDeckAj8X5K5YDxwH7gcdU9eos1TVrjLsbaqTfNdSH1nkJ88LrLM5HUTfLZ7X4lnTmRB466InKy57IrI9s5zpVxdRzncjMvAgaj8j+9Ye7oedV6N8VHYEW7kbL5WCzyqaxUWfh/fp5ufPTBGGk14mufxzOYWvHOzbSm/o62aCsKnXKm8rm0vQ5qHoO7IBCE09wYo+FggaPihOMQIIT81lVK0w9K6OvnDWfhXexWTifxXLgIqBdVVsyqlkOycsIbj+hYdeAhcXFLzBBBtQFobojplssPG/EtPT+GcMZZHc/5Lrcujdkp35BqJ0ZEZip5+Ru3ICG3Ntlouiz/u25uS+4LsxEFk3DgvReBnKFhpwPInbwp190chkKHkt1e/yggfB27YziTO+SLqHhAEIT0OoJH4+lZiq8MzM/XDa6oT5JxKIYxgub9ZbngqTpyDd5F4t00ZD7x/SLS1hgstVHW9EQx++y2Dn9MnHw9W2DHXfB9t/Cjt+6Ubj5YPHno30y+fBVDB3wRZ3FGVOTSydu7cz4Fk3DAue4LSbn7Eif+13Es27CQpSvSL2yymgrZ9al7rde2eSsm8qmcY9DKDo05EVF+YQkNAIdyzK6XDbE4j/xxlaoagEneAhO0YtFuqi6N8GuOOKSi8FfZZUw+10w510w/cLMLYDQiEtYuP1OJzCHXshuPWOpmTbW0d94pGto8+WEHOl3KdATjafJ5fwfVa1jLZrwfv1cKK/K3b0zRUNupLbfuhlj8WTJ11VWGRGOyuaY7SaoinOsstk77m1XNBZnxFoWyGo3VKkw4cQiE4YOehMVxQhM35bc3G/6W5y4zLokkj8qU/pfhx13R7Ky+h3/2R4bIBXxBabxyOwnX0xFaMR1kcVaNWGLJpdhvmXViS2abGYJyBUj/e7ZhS2c2mnO6T3cFQnmCOcJG+5yOdlGvLX/8yAWc0VDZkLjF6kitHJMLIxgDOyBbb+GrbfCzt/l/n4dp3vWixcPP1405PrZDzv7Y0KXs03NlPgC07gwuxFlQVF1I8GTZQnIJYezBMRYNA3zXT96kTWMcQk7tYcPeSKSptCEt4MEGEhFYoGJEqAkVlBFU1atHBMLIzeM9MLO38OWW2DrLbmbl2HKm6D5uGj/Szbf+Ef6XNRV7JiY7g3ZTzEvZYnHxaQbqJBthrsj3Wfx/DS5HEdS3ZE491nd7NIK4QVnIY50xxGTrvSEKIhvrKI+WkjqZsGZSWdwSIiJhVEchEZcBNbWW5zA5CKTaGVT/HDkdHN5pULVdQnFE5juDdnP81XdEV9gGo4obBhvmNEhr/snRmjCFk0u53WpqI8TebbATZFcM7V0o6gOWzlpCk1FLbzp9oxuaWJhlCaqrgHqfnlsOHK2Gp+yqvjhyA0Lc/M2O9LvGtF4ApOLQIV4STAbj/TmXimSbqHwYMWejS69Ts9G6PX5bMbrY6uod/mlqlp9i28/2WfltcXznPKAiYUxeRjcD10vjo0Yy+bI8aajxwpM01G581OEI+HiCUzXhuyH8Va1xReYxiMKkxI+FUMHfT4aX6LNzuWR+UyGD7r14cXbTzVwtawqIh6VccQkajtGeCobiyvMOQAmFoaRiJFeNyo/drxLzyvZu0f9vPh5xnIdXTQ6GLFiYgUmF1FVDUfEEZhFrg+9WBvN0IgTjkRikkxohg8m726UMi8aKoGYJBOaqpaC+GlMLNLhthlj8/PUTHXTiXac4datJxZnvLqRe0aHvGirOONdsuWnqJkav2usujP3XSLhiKp4AtO9IXvZCMJUtsQJW17klsrG7N4r22jIBQUkE5oxwuPbT/Usw6k7YsWlMo7QxO5naOWaWKTDuq/D2s+lX655cURMOs9wfd6TqK/TSEBo1EUY+f0t4SVb0UWVzT7LxZfEsm5O/n6Do0OuGyiewOQibYh/UrKwuDQd6b5zKQyYCzuvY4UllfCEP08WmlvdDn+WmU/PxGK8+Kca3bMKDjyV/jWkLFpMOpZDdVt26mdMHFRd4xrl0H/R+WFK1amfjIG9/P7Wl7n1JxuY27aBI6dv4MhpG1g07WXqqsc5sVVlswu7rm6Hqna3HrPd5taFGBczHkaHPOE4GC0swwfcb+jIv8nosgUXCxGpAR4CqoEK4BZVvVpE5gM3Au3AGuD9qjrGNhORK4EPA6PAJ1X196numbFYhMcKpBNuFxqFQ89HxGTvqszSild3+sTkDGg7acLkyTdyyOC+sX6XEnLqz5sHm+P8u8ydC5s2xSkQd1IyL51/39bIeY2L3LwVQ/vcM0o2q2J5XQIxibMdFpiqluL1xWRIMYiFAPWq2iMilcAjwKeAzwC/UtUbReQ64BlV/V5M2cXAL4BlwAzgXuBI1eRj8jMWi5tqx07uU14LU1a4uR6mrHCNeLpvYMM9sO/JiJjsWZVZgrWmo6P9J42LrLvLSI/hHpfKvkic+mVl7mU4FhEIZXO4ykh/RDgG93nb+6OPHT7urYcOJPZFSZnnI4gjLIksmKr24hgXk4CCi0VMZepwYvFx4LfANFUdEZHTgWtU9YKY868EUNV/8/Z/7533WLL7ZCwWr/4YnvhwemUq6j0xOdstLSdk1m/atz26u2t/ht1ofjHpWA41HZldxzDARVV1v5JTp/7OA9NYt31x1NJdtpinXujMyvUzRkOueydKRPaPFZbY7WT+qPLa9CyY6nYnSnmwYopCLESkHNfVdATwHeDfcVOzHuF9Phu4W1WPiyn3be+8//P2f+SdN2Y8u4hcAVwBMGfOnJM3x7NtM2FwH+x+GHY/4GZ9O/hseuUrm3xisgJajs/sDx8adf+gYTHZsyqzfD/V7U5Mmo5y20d8zOWZMYxskBenfku0vyVsvdTNKg5Le3QguQUTb3tofxLxFScYQfwv1Z3QenxG1S4KsfBVpgW4DfgX4IZsioWfvI6zGNjj0ljsut8JSrppuKtaI91cU8+G5mMzf4sY6YV9f/IJyiPjmzGv/TRY/E8uk+wE6581igRVfvXzHdz2kxdor3yRZUet47xT1jGlet24Mgzv6ppOf+MK5h3VCTWdrhENr8PbeXpjD4SGXNqOqC6x/cktmKF9YyOjaqbAO3dlVIWiEgsAEfkC0A98jmLrhsoF/btg94OeZfKAi2xJh+p2mHJ2xGfSvHh8b099O1x317qvw/4/ZX6dMPM/AMf8I7QcO/5rGUYQBvZGj9TvWkffznXUSSRMd/v+GQyM1DK7cw9VkmAOESmPvI3HE5PYY9XtxZfUcHQw2oIJDcL0N2d0qYKLhYh0AsOqelBEaoE/AF8DPgDc6nNwP6uq340peyzwcyIO7j8Ci3Lm4C4E/Tth14Ow+34nJumm066Z4nPAn+26l8YjJqERl6Z83dczCxOOpbLFWSeLPu4iSAwjBySNqnp10IUeD+5xPQH+dbztZBZNVVt8UYkrMB0lFdFYDGJxPPBToBwoA25W1S+KyAJc6Gwb8DTwPlUdFJGLgaWq+gWv/FXAh4AR4NOqeneqe5aUWKSib5snJg84MUk3aqVmWqSLa8rZLsfPePt1B/bCy9+FF78eLHd/KtqXwTH/5KbCLIVBVUbRkdWoqtCI19WzJ5jADO5N7G+obHKikcxi8R8rYP6tgotFIZhQYpGK3i2um2vX/W7p3ZTZddpPgzdc40zYbDgJD6yFF78Bm1aO7zptp8CUMyNRXrVTx183Y8KR9niNbKIhF2YbT0wSCUyi+V/Ka4N1iYW3K5uy5tQ3sZjs9GyKRHLteiDzlM+dZzoxmXp2dn6coVHY9ivPdzKOv1Vlc/RgxvZlRR3LbuSGlSvhiiugzxdwVVcH118Pl11WuHrFRdXNP5FITOIdSzSosKwqYrnUdLpZJ0/9YUbVMrEwEqMKr98Lz13jnN7jYerZ8IZ/dVZAthjpd054f7jw8MH0r9OwIDrdSvPi4omCMbLGypVw1VWwZQvMmQPXXluEQpEpI73JxSS8Lq+G8x7M6BYmFkbmqLr5uJ+9evyRU9MvcGLScWp26hamf1f0YMZ9j2d2nfZl0YJSOy279TSMIsfEwsgdqrD9N84yOfD0+K414yI4/hpoOzkbNYugIehaH51qpfvl9K9T2RQtJu3LoKIuu3U1jAJiYmEUDg3BttudZXLo+cyu0XAETDvPi+Y6KzcO7tEB2Lc6IiZ7VmU2IKx+fkRMOs8Y3wBLw8gzJhZG8RIahS2/hOevcW//mdB8rG+cyVnOyZcLBnbD3sd82YUz9PG0LY12yNfNyG49DSNDTCyM0kVDcPC5SCqVXQ+4lAjp0PKGaDGpbs9+PcF1yXWtj7ZO0h1gCW6GtKhkkKcW59zXxoTDxMKYuIRG4eAzTkTCYpJuLqyWEyKpVKae5fIF5YrRAdi/Jnruk8F96V+nfl60ddJ8rA1mNMaNiYUxeQmNuMGBYSHZ/UD6I85bT4xkDZ7yptxn6B3YG4nuClspmdB2crRDvm5mdutpTDhMLAwjEaER2P+Ub9Di/S4RWzq0nRxJpTLljXEn+Mkqqi6ayy8mXS+lf52K+pjorlOhsiH79TVKBhMLw8iU0LDrNgoLye4HEqdpSET7Mk9MVrhGubIxFzWNZnTQiaDffzK4J/3r1M2Jie56g3V3TWBMLAwjV4wOucGK4VQqux+A5AmRx9JxesQB33lG/pzZg/uio7v2PAJk0Aa0nhjxnUx5o5uAyMg72Ri9bmJhGIVidMDNve53wKfbIHeeEfGZdJyev4GAqm46Vb91ku5cLADlddHWSfup+bGuJhHZyotlYmEYxcpIP+x7IiImuzPI6dN5ZmTK3o7Tobwmy5VMwuiQm/PEH901sDv969TNjg4XbnlD8U0yVMRkK+OuiYVhlCojfbD38Yi/ZM8j6V/DP2Vv+6n5n4xncH+kuytspaTbVQfQuiTaIV8/J+tVLVWyNZeHiYVhTFRGemHPo5Forr1JZxsei5RFT9nbvgzKq3JQ0SSoQs/GaDFJdx57cBaVX0zy6f8pMGZZjAMTC8MAhrtd4xv2l+x7Ir3yZZW+0e8roP0UdyzfjA658TJ+/8nA66nL1Ux1XVz1c9y6bg7Ue+u62S6z8ATI3WU+i3FgYmEYARjugt2PRMQk3TT0ZdW+0e9nuzEnhfI1DB1wXXZhMWlfCkOH3GRffVvdjJIjPdFlyiqhdqYnJnOihSW8rmzO2kx0ucSioTLExMIwssDQQecn2fWA6+Y68FR65ctrI0IydYULsy2UmKi6vGK9nnj0bYHe8Dp8bBvoSHS5isZoayRWTOpm5TeoIIeYWBiGkRuGDsDuhyMO+ANr0ytf0RDtgG85obCD/kKjMLAr2hrxr/u2xI/2qpmSREzmuO6wEhjMWHCxEJHZwM+Aqbgg8+tV9VsichNwlHdaC3BQVZfEKb8J6AZGgZEgX8bEwjCKgMF9sPshLzT4fpdBOB0qmyKj36eugJbjC+9jGB1wFkgiMYnX3SUVzgJJJCb1s6GypeDdXcUgFtOB6ar6lIg0AmuAS1V1ne+c/wAOqeoX45TfBCxV1b1B72liYRglwMAeT0zud2JyaF3qMn6qWqMd8C3HFV5Mwt1dCcVkK/RvG5s2pqIhuTO+fnbOu7sKLhZjbiTya+DbqnqPty/AFuAcVR0z36WJhWFMUvp3uYGKYQd8OiPIp57j5n2vnwcN8926uqPgb++Am6dlYFdiMenb4j6PpboziZjMgZpp4+ruKiqxEJF5wEPAcara5R17E/CfiSopIq8BB3BdWN9X1esTnHcFcAXAnDlzTt4cL/DYMIyJQ/9O2PVgZJxJqsmmyuugYZ4TjvASFpL6eW5irGIQE3DJIGO7u2Kd8rFzt0gFNB0Fb8tsCuOiEQsRaQAeBK5V1V/5jn8PeEVV/yNBuZmqul1EpgD3AH+nqg8lu5dZFoZhMNwFPZug11v8272bnIPeT0V9fBEJC0xVW/GICXihwTFiEhqBE7+W0eWCikVO49lEpBK4FVgZIxQVwDuBkxOVVdXt3nq3iNwGLMNZJ4ZhGImpbILW490Sj6GD0Lt5rJD0vAZ7HnZi46eiIbGQ1M9zPpR8iklVs1tajsvfPcmhWHg+iR8BL6rqf8Z8fB7wkqpuS1C2HihT1W5v+83AGCe4YRhG2lS1uKX1hPifDx2MLyS9m+JP4VvZFNPFNS/aUqlqyf53KAC5tCzOAN4PPCcia71j/6yqdwHvAX7hP1lEZgA/VNW34sJtb3N6QwXwc1X9XQ7rahiG4ahqgaolLolhLKowfDAiJGER6d0Eva/BrvvGhtBWNo8VEb+lkuspe7OEDcozDMPIFqrOJxIrJIetlNfGzgdf2TLWGvFbKTmesrcofBaGYRiTChGobnNL20ljP1d1gxb9DvewkHS/DDv/AKN90WWqWpM74PM0qZSJhWEYRr4QgZoOt7THeZlXhcG98SO5ul6Cnb+D0f7oMlVt0LwYzn84p1U3sTAMwygWRKCm0y3tp4z9XBUG94x1vscmQswBJhaGYRilgohLYFgzBTqW5fXWpT8DiGEYhpFzTCwMwzCMlJhYGIZhGCkxsTAMwzBSYmJhGIZhpMTEwjAMw0iJiYVhGIaREhMLwzAMIyUTKpGgiOwB/FPldQCBp2UtIqze+cXqnV+s3vknWd3nqmpnqgtMKLGIRURWB8mmWGxYvfOL1Tu/WL3zTzbqbt1QhmEYRkpMLAzDMIyUTHSxuL7QFcgQq3d+sXrnF6t3/hl33Se0z8IwDMPIDhPdsjAMwzCygImFYRiGkZKSEwsRmS0i94vIOhF5QUQ+FeccEZH/FpFXRORZETnJ99kHRORlb/lAkdX7Mq++z4nIoyJygu+zTd7xtSKyOl/1TqPuK0TkkFe/tSLyBd9nF4rIeu/v8fkiq/c/+ur8vIiMikib91lBnrmI1IjIkyLyjFfvf41zTrWI3OQ90ydEZJ7vsyu94+tF5IIiq/dnvL/HsyLyRxGZ6/ts1Pe3uKPI6n25iOzx1e8jvs8K1aYEqfc3fXXeICIHfZ+l97xVtaQWYDpwkrfdCGwAFsec81bgbkCA04AnvONtwEZv3epttxZRvZeH6wO8JVxvb38T0FHEz3wFcGecsuXAq8ACoAp4JrZsIesdc/7bgfsK/cy9322Dt10JPAGcFnPO3wDXedvvAW7ythd7z7gamO89+/IiqvfZQJ23/fFwvb39nnw/6zTqfTnw7ThlC9mmpKx3zPl/B/w40+ddcpaFqu5U1ae87W7gRWBmzGmXAD9Tx+NAi4hMBy4A7lHV/ap6ALgHuLBY6q2qj3r1AngcmJWPuqUi4DNPxDLgFVXdqKpDwI24v0/OyaDe7wV+kY+6JcP73fZ4u5XeEhuJcgnwU2/7FuBcERHv+I2qOqiqrwGv4P4GOSdIvVX1flXt83aL4jce8HknopBtSrr1Htfvu+TEwo9nep+IU1Q/M4Gtvv1t3rFEx/NKknr7+TDOOgqjwB9EZI2IXJHD6iUlRd1P90ziu0XkWO9YSTxzEanD/ZPf6jtcsGcuIuUishbYjWuMEv7GVXUEOAS0U+DnHaDefmJ/4zUislpEHheRS3NYzTEErPefed1nt4jIbO9YSTxvr7tvPnCf73Baz7siC/UtCCLSgPvH/rSqdhW6PkEJUm8RORv3j/RG3+E3qup2EZkC3CMiL6nqQ7mvcVS9ktX9KVyOmR4ReStwO7Aon/VLRMDfytuBVaq633esYM9cVUeBJSLSAtwmIsep6vP5uPd4CFpvEXkfsBQ4y3d4rve8FwD3ichzqvpqkdT7N8AvVHVQRD6Ks+rOyUfdkpHG7+Q9wC3e+WHSet4laVmISCXun3+lqv4qzinbgdm+/VnesUTH80KAeiMixwM/BC5R1X3h46q63VvvBm4jT10LvnolrbuqdoVNYlW9C6gUkQ5K4Jl7vIcYE73Qz9y790HgfsZ2bRx+riJSATQD+yjw8w6TpN6IyHnAVcDFqjroKxN+3huBB3CWYF5JVG9V3eer6w+Bk73ton/eHsl+38GedzoOjmJYcE6dnwH/leSctxHt4H5SI86o13COqFZvu62I6j0H18e8POZ4PdDo234UuLDInvk0IoM8lwFbvHIVOKfffCIO7mOLpd7eec3AfqC+GJ450Am0eNu1wMPARTHnfIJoB/fN3vaxRDu4N5I/B3eQep+Ic7ovijneClR72x3Ay+QvECJIvaf7tt8BPO5tF7JNSVlv77OjccEaMp7nXYrdUGcA7wee8/rqAP4Z19CiqtcBd+Eiol4B+oAPep/tF5EvAX/yyn1Ro7sdCl3vL+D6nb/rfJWMqMsUORVnYoJrfH+uqr/LU72D1v1dwMdFZAToB96j7pc4IiJ/C/weFxn1Y1V9oYjqDe6f/w+q2usrW8hnPh34qYiU46z/m1X1ThH5IrBaVe8AfgT8r4i8ghO69wCo6gsicjOwDhgBPqHRXQ+Frve/Aw3AL71nu0VVLwaOAb4vIiGv7FdVdV0R1fuTInIx7pnux0VHFbpNCVJvcL+NG73/xzBpP29L92EYhmGkpCR9FoZhGEZ+MbEwDMMwUmJiYRiGYaTExMIwDMNIiYmFYRiGkRITC2PSEJNlc634MrUGKHupiCz27X/RG1yGiDwgIku97btEpMVb/ibN+s0TkX6vbutE5GfeoMJkZVaIyPJ07mMYmWBiYUwm+lV1iW/ZFKSQN0L6UlxGVwBU9Quqem/suar6VnWjaVtwmWHT5VVVXQK8ATca+M9TnL8Cl63YMHKKiYUxqRGRk0XkQS9Z4O+97MRha+G/xM1j8TngYuDfvbf+hSJyg4i8K871NnlpTr4KLPTO/3fPSrjUd95KEUmYfdcbSPckXlI6EXm7uHkrnhaRe0VkqmcZfQz4e+8+Z4pIp4jcKiJ/8pYzsvawjElNKY7gNoxMqfWN5H4N99b+P7g8XHtE5C+Aa4EPeedUeSPoEZFFuPk6bvH2U93r88BxnpWAiJwF/D1wu4g046yBhBPliEgNcCoQnrDpEdxcBSpu4p1/UtV/EJHrcPMSfMMr93Pgm6r6iIjMwY2cPyb1ozGM5JhYGJOJ/nDjDSAixwHH4TLKgktHstN3/k3ZurGqPigi3xWRTuDPgFvVpRaPZaEnaPOB36rqs97xWcBNnuVThRO7eJwHLPaJWZOINGhk3gPDyAgTC2MyI8ALqnp6gs97ExzPlJ8B78Pl6vlggnNeVdUlXlfWKhG52Mvx8z/Af6rqHSKyArgmQfkynAUykNWaG5Me81kYk5n1QKeInA4unblEJm2KpRs3NWtQ4p1/A/BpgFRJ21R1L64r60rvUDOR1Nf+7qvY+/wBN30mACKyJI06G0ZCTCyMSYu6aV7fBXxNRJ4B1pI4suhG4B89B/PCANfeh7MMnheRf/eO7cJN7fqTgFW8HagTkTNxlsQvRWQNsNd3zm+Ad4Qd3MAngaXiZnRbh3OAG8a4sayzhpEnxE3d+hxwkqoeKnR9DCMdzLIwjDzgDeB7EfgfEwqjFDHLwjAMw0iJWRaGYRhGSkwsDMMwjJSYWBiGYRgpMbEwDMMwUmJiYRiGYaTk/wNCs5WBipPtsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = 0.66\n",
    "\n",
    "evaluate_ridge_regression(dataset, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 4.1",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 4.2",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 4.3",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 4.4",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 4.5",
     "locked": true,
     "points": "4",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Part 5: Artificial Neural Network\n",
    "\n",
    "Write a programme that can classify two different type of data points with high accuracy.\n",
    "\n",
    "\n",
    "### Assessment task:\n",
    "\n",
    "Write code to develop artificial neural network using the moons dataset. There are 20 steps involved, you will complete the code for steps 2, 3, 4, 5, 9, 10, 11, 12, 13 and 16 only.\n",
    "\n",
    "### Marks:\n",
    "\n",
    "This part is of 6 Marks. \n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Write your Python code in place of \"your code here\" placeholder below.\n",
    "2. Run your code by clicking on 'run' cell in the toolbar before you submit.\n",
    "3. You will get the feedback once you submit the assignment.\n",
    "\n",
    "### Submission:\n",
    "\n",
    "Click on the submit button on the top right after you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "Load a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    # Opens the file in read only mode\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            dataset.append(row)\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "extract only x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_only_x_data(dataset):\n",
    "    if len(dataset) == 0:\n",
    "        return\n",
    "    \n",
    "    data = list()\n",
    "    \n",
    "    for i in range(0, len(dataset)):\n",
    "        data.append(list())\n",
    "    \n",
    "        for j in range(0, len(dataset[i]) - 1):\n",
    "            data[-1].append(float(dataset[i][j]))\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "extract only y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_only_y_data(dataset):\n",
    "    if len(dataset) == 0:\n",
    "        return\n",
    "    \n",
    "    data = list()\n",
    "    \n",
    "    for i in range(0, len(dataset)):\n",
    "        data.append(int(dataset[i][-1]))\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "Defining the Config that contains the inputs for the network, the outputs for the network as well as the parameters for gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    neural_network_input_dimension = 2\n",
    "    neural_network_output_dimension = 2\n",
    "    learning_rate = 0.01\n",
    "    regularization_strength = 0.01\n",
    "    #Specify input layer dimensionality,  output layer dimensionality, learning rate for gradient descent, regularization strength\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6\n",
    "Load the moons.csv data, extract the data and convert it into num py arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    filename = 'moons.csv'\n",
    "\n",
    "    dataset = load_csv(filename)                            # load the data from a csv file\n",
    "\n",
    "    x_data = extract_only_x_data(dataset)                   # extract the input data (2 inputs)\n",
    "    y_data = extract_only_y_data(dataset)                   # extract the output data (1 output)\n",
    "    \n",
    "    X = np.array(x_data)                                    # convert the data into np array\n",
    "    y = np.array(y_data)                                    # convert the data into np array\n",
    "\n",
    "    return X, y                                             # returns both input (X) data and output (y) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "Assign the X and y with the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "Draw the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))                              # Defines the size of the plot\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.Spectral)  # Draws a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "Define a activation function of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    # Return the value of the implemented activation function, do not simply return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10\n",
    "Define a lost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(a):\n",
    "    epsilon = 1e-15\n",
    "    a = np.clip(a, epsilon, 1 - epsilon)\n",
    "    return - (np.log(a))\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    # Return the value of the implemented loss function, do not simply return a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "Define a weight regularization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_regularization(Wx, dWx):\n",
    "    return dWx + Config.regularization_strength * Wx\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    # Return the value of the implemented weight regularization function, do not simply return dWx\n",
    "    return dWx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "Define forward propagation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = activation_function(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    \n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    \n",
    "    return np.exp(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13\n",
    "Define backward propagation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, W1, b1, W2, b2, exp_scores, number_of_examples):\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        \n",
    "    delta3 = probs\n",
    "    delta3[range(number_of_examples), y] -= 1\n",
    "\n",
    "    z2 = np.dot(X, W1) + b1\n",
    "    a1 = np.tanh(z2)\n",
    "\n",
    "    dW2 = (a1.T).dot(delta3)\n",
    "    db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "\n",
    "    delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "    \n",
    "    dW1 = np.dot(X.T, delta2)\n",
    "    \n",
    "    # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "    db1 = np.sum(delta2, axis=0)\n",
    "    \n",
    "    dW1 += Config.regularization_strength * W1\n",
    "    dW2 += Config.regularization_strength * W2\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    return dW1, dW2, db1, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 14\n",
    "Define the loss function, used to evaluate how well the model is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model, X, y):\n",
    "   \n",
    "    number_of_examples = len(X)\n",
    "    \n",
    "    W1 = model['W1']\n",
    "    b1 = model['b1']\n",
    "    W2 = model['W2']\n",
    "    b2 = model['b2']\n",
    "    \n",
    "    exp_scores = forward_propagation(X, W1, b1, W2, b2)\n",
    "    \n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    \n",
    "    # Calculating the loss\n",
    "    \n",
    "    correct_probs = loss(probs[range(number_of_examples), y])\n",
    "    \n",
    "    data_loss = np.sum(correct_probs)\n",
    "    \n",
    "    data_loss = data_loss + Config.regularization_strength / 2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "    \n",
    "    return 1. / number_of_examples * data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15\n",
    "Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    W1 = model['W1']\n",
    "    b1 = model['b1']\n",
    "    W2 = model['W2']\n",
    "    b2 = model['b2']\n",
    "    \n",
    "    exp_scores = forward_propagation(X, W1, b1, W2, b2)\n",
    "    \n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    \n",
    "    return np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 16\n",
    "Build the neural network using batch gradient descent using the backpropagation derivates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(X, y, number_of_nodes_within_hidden_layer, passes=20000, print_loss=False):\n",
    "\n",
    "    # Initialize the parameters to random values. We need to learn these\n",
    "    \n",
    "    \n",
    "    number_of_examples = len(X)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Two weights are needed as the network has two inputs\n",
    "    # Likewise, two biases are needed as the network has two inputs\n",
    "    \n",
    "    # Initialize weights and biases\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = Config.neural_network_output_dimension\n",
    "    W1 = np.random.randn(input_dim, number_of_nodes_within_hidden_layer) / np.sqrt(input_dim)\n",
    "    b1 = np.zeros((1, number_of_nodes_within_hidden_layer))\n",
    "    W2 = np.random.randn(number_of_nodes_within_hidden_layer, output_dim) / np.sqrt(number_of_nodes_within_hidden_layer)\n",
    "    b2 = np.zeros((1, output_dim))\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    \n",
    "    model = {}\n",
    "    \n",
    "    for i in range(0, passes):\n",
    "        # Forward Propgation\n",
    "        exp_scores = forward_propagation(X, W1, b1, W2, b2)\n",
    "        \n",
    "        # Back Propgation\n",
    "        dW1, dW2, db1, db2 = backward_propagation(X, y, W1, b1, W2, b2, exp_scores, number_of_examples);\n",
    "        \n",
    "        # Gradient descent parameter update\n",
    "        \n",
    "        \n",
    "        W1 -= Config.learning_rate * dW1\n",
    "        b1 -= Config.learning_rate * db1\n",
    "        W2 -= Config.learning_rate * dW2\n",
    "        b2 -= Config.learning_rate * db2\n",
    "\n",
    "        ###\n",
    "        ### YOUR CODE HERE\n",
    "        ###\n",
    "        \n",
    "        # Assign new parameters to the model\n",
    "        \n",
    "        model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "        \n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "        result = calculate_loss(model, X, y)\n",
    "        \n",
    "        if print_loss and i % 1000 == 0:\n",
    "            print(\"Loss after iteration %i: %f\" % (i, result))\n",
    "            \n",
    "            if result > 2.0:\n",
    "                print(\"Loss is too high\")\n",
    "                break\n",
    "            \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 17\n",
    "Train the model\n",
    "\n",
    "Note: 10,000 passes is used in the auto graders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model(X, y, 3, print_loss=True, passes=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 18\n",
    "Plot Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(pred_func, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    \n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the contour and training examples\n",
    "    plt.title(\"Artificial Neural Network\")\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 19\n",
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize(X, y, model):\n",
    "    plot_decision_boundary(lambda x:predict(model, x), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 20\n",
    "Call the visualize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    visualize(X, y, model)\n",
    "except:\n",
    "    print(\"Can not visualize the graph, the data or the model is inconsistent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 5.1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 5.2",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Part 5.3",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
